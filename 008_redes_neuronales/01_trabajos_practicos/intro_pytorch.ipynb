{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"indice\"></a> \n",
    "## Índice de la notebook\n",
    "\n",
    "[1) BUILDING TENSORS](#1)\n",
    "\n",
    "[2) BASIC OPERATIONS IN PYTORCH](#2)\n",
    "\n",
    "[3) SLICING IN PYTORCH](#3)\n",
    "\n",
    "[4) NUMPY AND PYTORCH](#4)\n",
    "\n",
    "[5) USING GPU IN PYTORCH](#5)\n",
    "\n",
    "[6) GRADIENTS IN PYTORCH](#6)\n",
    "\n",
    "[7) BACKPROPAGATION](#7)\n",
    "\n",
    "[8) OPTIMAZATION AND OPTIMAZERS](#8)\n",
    "\n",
    "[9) GENERAL TRAINING PIPELINE](#9)\n",
    "\n",
    "[10) IMPLEMENTING LINEAR REGRESSION (REGRESSION)](#10)\n",
    "\n",
    "[11) IMPLEMENTING LOGISTIC REGRESSION (CLASSIFICATION)](#11)\n",
    "\n",
    "[12) DATASETS AND DATALOADERS CLASSES](#12)\n",
    "\n",
    "[13) DATASETS TRANSFORMS](#13)\n",
    "\n",
    "[14) SOFTMAX AND CROSS-ENTROPY](#14) <br>\n",
    "        - [BINARY CLASS CLASSIFICATION PROBLEMS](#15) <br>\n",
    "        - [MULTI CLASS CLASSIFICATION PROBLEMS](#16)\n",
    "\n",
    "[15) FEED FORWARD NETWORKS](#17)\n",
    "\n",
    "[16) CONVOLUTIONAL NEURAL NET (CNN)](#18)\n",
    "\n",
    "[17) TENSORBOARD WITH PYTORCH](#19)\n",
    "\n",
    "[18) SAVING AND LOADING MODELS](#20)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> \n",
    "### 1) BUILDING TENSORS\n",
    "\n",
    "[Ir a índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/csuarezgurruchaga/Desktop/UDESA/008_redes_neuronales/01_trabajos_practicos/intro_pytorch.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/csuarezgurruchaga/Desktop/UDESA/008_redes_neuronales/01_trabajos_practicos/intro_pytorch.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/csuarezgurruchaga/Desktop/UDESA/008_redes_neuronales/01_trabajos_practicos/intro_pytorch.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mempty(\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/csuarezgurruchaga/Desktop/UDESA/008_redes_neuronales/01_trabajos_practicos/intro_pytorch.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m x\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/redes/lib/python3.8/site-packages/torch/__init__.py:219\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[39m# Easy way.  You want this most of the time, because it will prevent\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[39m# C++ symbols from libtorch clobbering C++ symbols from other\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# See Note [Global dependencies]\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[0;32m--> 219\u001b[0m         _load_global_deps()\n\u001b[1;32m    220\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39m# Appease the type checker; ordinarily this binding is inserted by the\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[39m# torch._C module initialization code in C\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/redes/lib/python3.8/site-packages/torch/__init__.py:174\u001b[0m, in \u001b[0;36m_load_global_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m lib_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(here), \u001b[39m'\u001b[39m\u001b[39mlib\u001b[39m\u001b[39m'\u001b[39m, lib_name)\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     ctypes\u001b[39m.\u001b[39;49mCDLL(lib_path, mode\u001b[39m=\u001b[39;49mctypes\u001b[39m.\u001b[39;49mRTLD_GLOBAL)\n\u001b[1;32m    175\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    176\u001b[0m     \u001b[39m# Can only happen of wheel with cublas as PYPI deps\u001b[39;00m\n\u001b[1;32m    177\u001b[0m     \u001b[39m# As PyTorch is not purelib, but nvidia-cublas-cu11 is\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mlibcublas.so.11\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m err\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/redes/lib/python3.8/ctypes/__init__.py:381\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_FuncPtr \u001b[39m=\u001b[39m _FuncPtr\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m _dlopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name, mode)\n\u001b[1;32m    382\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    383\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m handle\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.empty(2,2,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4484, 0.0385],\n",
       "        [0.1815, 0.4336]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2,2)\n",
    "(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double its a float64 which its different from dtype = torch.float which is float 32\n",
    "x = torch.ones(2,2, dtype = torch.double)\n",
    "(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5000, 0.7000], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([2.5, 0.7], dtype = torch.double)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> \n",
    "### 2) BASIC OPERATIONS IN PYTORCH\n",
    "[Ir a índice](#indice)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9666, 0.8989],\n",
       "         [0.6205, 0.7627]]),\n",
       " tensor([[0.7642, 0.7215],\n",
       "         [0.3198, 0.2377]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2,2)\n",
    "y = torch.rand(2,2)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7308, 1.6204],\n",
       "        [0.9403, 1.0004]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x + y\n",
    "z = torch.add(x,y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7642, 0.7215],\n",
      "        [0.3198, 0.2377]])\n",
      "new tensor with x added: \n",
      "tensor([[1.7308, 1.6204],\n",
      "        [0.9403, 1.0004]])\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "y.add_(x) # Each function in pytorch which has '_' will do an Inplace Operation\n",
    "# will update the value each.\n",
    "\n",
    "print(f'new tensor with x added: \\n{y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7642, -0.7215],\n",
       "        [-0.3198, -0.2377]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x - y\n",
    "z = torch.sub(x, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6730, 1.4565],\n",
       "        [0.5835, 0.7630]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x * y\n",
    "z = torch.mul(x,y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6730, 1.4565],\n",
       "        [0.5835, 0.7630]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mul_(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9666, 0.8989],\n",
       "        [0.6205, 0.7627]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x / y\n",
    "z = torch.div(x,y)\n",
    "z"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a> \n",
    "### 3) SLICING IN PYTORCH\n",
    "[Ir a índice](#indice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7110, 0.0704],\n",
      "        [0.8379, 0.0723],\n",
      "        [0.0887, 0.2006],\n",
      "        [0.9964, 0.0470],\n",
      "        [0.8094, 0.5816]])\n",
      "Only print the first column and all the rows: \n",
      "tensor([0.7110, 0.8379, 0.0887, 0.9964, 0.8094])\n",
      "\n",
      "Only print the second row and all the columns: \n",
      "tensor([0.8379, 0.0723])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 2)\n",
    "print(x)\n",
    "\n",
    "print(f'Only print the first column and all the rows: \\n{x[:,0]}')\n",
    "print(f'\\nOnly print the second row and all the columns: \\n{x[1,:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07225489616394043"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1,1].item() # para seleccionar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6450, 0.6242, 0.8454, 0.2802],\n",
      "        [0.4245, 0.1617, 0.9815, 0.0456],\n",
      "        [0.5908, 0.6886, 0.1957, 0.0879],\n",
      "        [0.9852, 0.1074, 0.9075, 0.4201]])\n",
      "\n",
      "\n",
      "tensor([0.6450, 0.6242, 0.8454, 0.2802, 0.4245, 0.1617, 0.9815, 0.0456, 0.5908,\n",
      "        0.6886, 0.1957, 0.0879, 0.9852, 0.1074, 0.9075, 0.4201])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4,4)\n",
    "print(x)\n",
    "print('\\n')\n",
    "y = x.view(16) #reshape\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.view(-1, 2) #reshape, if we put '-1', and one of the dimentions,\n",
    "                  # pytorch will automatically determinate the right size\n",
    "y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "### 4) NUMPY AND PYTORCH\n",
    "[Ir a índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = torch.ones(5)\n",
    "print(type(a))\n",
    "\n",
    "\n",
    "b = a.numpy()\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a> \n",
    "### 5) USING GPU IN PYTORCH\n",
    "[Ir a índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FOR WINDOWS\n",
    "if torch.cuda.is_available(): # Check if there is an GPU avaible\n",
    "    device=torch.device(\"cuda\")\n",
    "    x = torch.ones(5, device = device) # this creates a tensor and put it in the GPU\n",
    "    \n",
    "    y = torch.ones(5)\n",
    "    y = y.to(device) # move the tensor to the device (GPU)\n",
    "    \n",
    "# If we want to convert a tensor to numpy array, we have first to send it to cpu, numpy does't work on gpu\n",
    "\n",
    "    z = x + y\n",
    "    z = z.to(\"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a> \n",
    "### 6) GRADIENTS IN PYTORCH\n",
    "[Ir a índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(5, requires_grad= True, dtype= torch.double)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5796, 4.3735, 0.1492], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad = True) # random normal distribution istead uniform\n",
    "\n",
    "y = x + 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.4300, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y*y*2\n",
    "z = z.mean()\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.1062, 5.8313, 0.1989])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.backward() # dz/dx (note: only works if \"z\" is scalar)\n",
    "# each time we call the .backward() method the gradient will be sum up the last value calculated\n",
    "\n",
    "x.grad #dz/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4204,  2.3735, -1.8508])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To deatach the tracking of the gradiant in pytorch\n",
    "# 3 ways\n",
    "# 1: x.requires_grad_(False)\n",
    "# 2: x.detach()\n",
    "# 3: with torch.no_grad():\n",
    "\n",
    "x.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4204,  2.3735, -1.8508])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.detach() # creates a new vector with the same values but not requires gradient\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5796, 4.3735, 0.1492])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y = x + 2\n",
    "    print(y) # here we see that our y doesn't have the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor([9., 9., 9., 9.])\n",
      "tensor([12., 12., 12., 12.])\n"
     ]
    }
   ],
   "source": [
    "# HERE WE SEE HOW THE .backward() METHOD ADD UP THE GRADIENTS\n",
    "weights = torch.ones(4, requires_grad = True)\n",
    "\n",
    "for epoch in range(4):\n",
    "    model_output = (weights * 3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "weights = torch.ones(4, requires_grad = True)\n",
    "\n",
    "for epoch in range(4):\n",
    "    model_output = (weights * 3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_() # ERASE THE GRADIENT FROM A VARIABLE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a> \n",
    "### 7) BACKPROPAGATION\n",
    "[Ir a índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.)\n",
    "y = torch.tensor(2.)\n",
    "\n",
    "w = torch.tensor(1., requires_grad = True)\n",
    "\n",
    "# forward pass and compute the loss\n",
    "y_hat = w * x\n",
    "loss = (y - y_hat)**2\n",
    "\n",
    "print(loss)\n",
    "\n",
    "# backward pass\n",
    "loss.backward()\n",
    "print(w.grad) #dloss/dw (returns the value in the leaf node)\n",
    "\n",
    "### update the weights\n",
    "### next forward and backward passes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a> \n",
    "### 8)OPTIMAZATION AND OPTIMAZERS<br>\n",
    "GRADIENTS OPTIMIZATION FROM SCRATCH USING NUMPY\n",
    "\n",
    "[Ir a índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5): 0.000\n",
      "epoch1 : w = 1.200, loss = 30.00000000\n",
      "epoch2 : w = 1.680, loss = 4.79999924\n",
      "epoch3 : w = 1.872, loss = 0.76800019\n",
      "epoch4 : w = 1.949, loss = 0.12288000\n",
      "epoch5 : w = 1.980, loss = 0.01966083\n",
      "epoch6 : w = 1.992, loss = 0.00314570\n",
      "epoch7 : w = 1.997, loss = 0.00050332\n",
      "epoch8 : w = 1.999, loss = 0.00008053\n",
      "epoch9 : w = 1.999, loss = 0.00001288\n",
      "epoch10 : w = 2.000, loss = 0.00000206\n",
      "Prediction after training: f(5): 9.999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# f = w * x\n",
    "# f = 2 * x\n",
    "\n",
    "X = np.array([1, 2, 3, 4], dtype = np.float32)\n",
    "Y = np.array([2, 4, 6, 8], dtype = np.float32)\n",
    "\n",
    "w = 0.\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted - y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# MSE = 1/N * (y - w*x)**2\n",
    "# dJ/dw = 2*x * 1/N * (y - w*x)\n",
    "def gradient(x, y, y_predicted):\n",
    "    return (np.dot(2*x, y_predicted - y)).mean()\n",
    "\n",
    "print(f'Prediction before training: f(5): {forward(5):.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 1e-2\n",
    "n_iter = 10\n",
    "\n",
    "for epoch in range(n_iter):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    dw = gradient(X, Y, y_pred)\n",
    "    \n",
    "    # update weights\n",
    "    w = w - (learning_rate * dw) # w -= learning_rate * dw\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(f'epoch{epoch + 1} : w = {w:.3f}, loss = {l:.8f}')\n",
    "        \n",
    "print(f'Prediction after training: f(5): {forward(5):.3f}')        \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOW WITH PYTORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5): tensor([0.], grad_fn=<MulBackward0>)\n",
      "epoch1 : w = tensor([0.3000], requires_grad=True), loss = 30.00000000\n",
      "epoch11 : w = tensor([1.6653], requires_grad=True), loss = 1.16278565\n",
      "epoch21 : w = tensor([1.9341], requires_grad=True), loss = 0.04506890\n",
      "epoch31 : w = tensor([1.9870], requires_grad=True), loss = 0.00174685\n",
      "epoch41 : w = tensor([1.9974], requires_grad=True), loss = 0.00006770\n",
      "epoch51 : w = tensor([1.9995], requires_grad=True), loss = 0.00000262\n",
      "epoch61 : w = tensor([1.9999], requires_grad=True), loss = 0.00000010\n",
      "epoch71 : w = tensor([2.0000], requires_grad=True), loss = 0.00000000\n",
      "epoch81 : w = tensor([2.0000], requires_grad=True), loss = 0.00000000\n",
      "epoch91 : w = tensor([2.0000], requires_grad=True), loss = 0.00000000\n",
      "Prediction after training: f(5): 9.999998092651367\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# f = w * x\n",
    "# f = 2 * x\n",
    "\n",
    "X = torch.tensor([1, 2, 3, 4], dtype = torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype = torch.float32)\n",
    "\n",
    "w = torch.tensor([0.], dtype = torch.float32, requires_grad = True)\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted - y)**2).mean()\n",
    "\n",
    "print(f'Prediction before training: f(5): {forward(5)}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 1e-2\n",
    "n_iter = 100\n",
    "\n",
    "for epoch in range(n_iter):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    # update weights\n",
    "    with torch.no_grad():    \n",
    "        w -= learning_rate * w.grad\n",
    "        \n",
    "    # zero gradients\n",
    "    w.grad.zero_()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch{epoch + 1} : w = {w}, loss = {l:.8f}')\n",
    "        \n",
    "print(f'Prediction after training: f(5): {forward(5).item()}')        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"9\"></a> \n",
    "### 9)GENERAL TRAINING PIPELINE<br>\n",
    "- **1) Desing model (input, output size, forward pass)**\n",
    "- **2) Construct loss and optimizer**\n",
    "- **3) Training loop**\n",
    "\n",
    "    - **a) forward pass and loss calculation:** compute the prediction and the loss value\n",
    "    - **b) backward pass:** calculate the gradients\n",
    "    - **c) update the weights** `optimizer.step()`,and reset the gradient `optimizer.zero_grad()`\n",
    "\n",
    "\n",
    "Now instead of using our loss function, we will  `import torch.nn as nn` and get the loss function from there.\n",
    "\n",
    "And we will use the optimizer provided from `torch.optim.SGD()` instead of actualize the weights by hand:\n",
    "\n",
    "    - update weights : optimizer.step()    \n",
    "    - zero gradients: optimizer.zero_grad()\n",
    "\n",
    "[Ir a índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5): tensor([0.], grad_fn=<MulBackward0>)\n",
      "epoch1 : w = tensor([0.3000], requires_grad=True), loss = 30.00000000\n",
      "epoch11 : w = tensor([1.6653], requires_grad=True), loss = 1.16278565\n",
      "epoch21 : w = tensor([1.9341], requires_grad=True), loss = 0.04506890\n",
      "epoch31 : w = tensor([1.9870], requires_grad=True), loss = 0.00174685\n",
      "epoch41 : w = tensor([1.9974], requires_grad=True), loss = 0.00006770\n",
      "epoch51 : w = tensor([1.9995], requires_grad=True), loss = 0.00000262\n",
      "epoch61 : w = tensor([1.9999], requires_grad=True), loss = 0.00000010\n",
      "epoch71 : w = tensor([2.0000], requires_grad=True), loss = 0.00000000\n",
      "epoch81 : w = tensor([2.0000], requires_grad=True), loss = 0.00000000\n",
      "epoch91 : w = tensor([2.0000], requires_grad=True), loss = 0.00000000\n",
      "Prediction after training: f(5): 9.999998092651367\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# f = w * x\n",
    "# f = 2 * x\n",
    "\n",
    "X = torch.tensor([1, 2, 3, 4], dtype = torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype = torch.float32)\n",
    "\n",
    "w = torch.tensor([0.], dtype = torch.float32, requires_grad = True)\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "\n",
    "print(f'Prediction before training: f(5): {forward(5)}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 1e-2\n",
    "n_iter = 100\n",
    "\n",
    "loss = nn.MSELoss() #MSE\n",
    "optimizer = torch.optim.SGD([w], lr = learning_rate)\n",
    "\n",
    "for epoch in range(n_iter):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "        \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch{epoch + 1} : w = {w}, loss = {l:.8f}')\n",
    "        \n",
    "print(f'Prediction after training: f(5): {forward(5).item()}')      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will replace our manually forward implementation\n",
    "\n",
    "now, we dont need w = 0, because the model already knows the initialization of the weights\n",
    "\n",
    "n_samples, n_features = X.shape[0], X.shape[1]\n",
    "\n",
    "input_size = n_features\n",
    "\n",
    "output_size = n_features\n",
    "\n",
    "model = nn.Linear(in_features = input_size, out_features= output_size)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5): 2.185\n",
      "epoch1 : w = 0.850, loss = 21.05941010\n",
      "epoch11 : w = 1.898, loss = 0.55876809\n",
      "epoch21 : w = 2.064, loss = 0.02755787\n",
      "epoch31 : w = 2.088, loss = 0.01305160\n",
      "epoch41 : w = 2.090, loss = 0.01195816\n",
      "epoch51 : w = 2.088, loss = 0.01125349\n",
      "epoch61 : w = 2.085, loss = 0.01059824\n",
      "epoch71 : w = 2.083, loss = 0.00998138\n",
      "epoch81 : w = 2.080, loss = 0.00940039\n",
      "epoch91 : w = 2.078, loss = 0.00885325\n",
      "Prediction after training: f(5): 10.157\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# f = w * x\n",
    "# f = 2 * x\n",
    "\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype = torch.float32)\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype = torch.float32)\n",
    "\n",
    "X_test = torch.tensor([5.])\n",
    "n_samples, n_features = X.shape[0], X.shape[1]\n",
    "# print(n_samples, n_features)\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "model = nn.Linear(in_features = input_size, out_features= output_size)\n",
    "\n",
    "print(f'Prediction before training: f(5): {model(X_test).item():.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 1e-2\n",
    "n_iter = 100\n",
    "\n",
    "loss = nn.MSELoss() #MSE\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "for epoch in range(n_iter):\n",
    "    # prediction = forward pass\n",
    "    y_pred = model(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "        \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        [w, bias] = model.parameters()\n",
    "        print(f'epoch{epoch + 1} : w = {w[0][0].item():.3f}, loss = {l:.8f}')\n",
    "        \n",
    "print(f'Prediction after training: f(5): {model(X_test).item():.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"10\"></a> \n",
    "### 10)IMPLEMENTING LINEAR REGRESSION (REGRESSION)<br>\n",
    "\n",
    "\n",
    "[Ir a índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:99, loss: 566.4654\n",
      "epoch:199, loss: 342.6889\n",
      "epoch:299, loss: 333.0143\n",
      "epoch:399, loss: 332.5874\n",
      "epoch:499, loss: 332.5685\n",
      "epoch:599, loss: 332.5676\n",
      "epoch:699, loss: 332.5675\n",
      "epoch:799, loss: 332.5676\n",
      "epoch:899, loss: 332.5676\n",
      "epoch:999, loss: 332.5676\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0) prepare data\n",
    "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features= 1, noise= 20, random_state= 1)\n",
    "X, y = torch.tensor(X_numpy, dtype=torch.float32), torch.tensor(y_numpy, dtype = torch.float32)\n",
    "y = y.view(-1, 1) # == y.view(y.shape[0],1)\n",
    "\n",
    "n_sample, n_features = X.shape\n",
    "# 1) model\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "\n",
    "model = nn.Linear(in_features=input_size ,out_features=output_size)\n",
    "\n",
    "# 2) loss and optimizer\n",
    "learning_rate = 1e-2\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)\n",
    "\n",
    "# 3) training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    #forward pass and loss\n",
    "    y_pred = model(X)\n",
    "    loss = criterion(y_pred, y)   \n",
    "    \n",
    "    #backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    #update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    #reset the gradients\n",
    "    optimizer.zero_grad()\n",
    "    if (epoch + 1) % 100 ==0:\n",
    "        print(f'epoch:{epoch}, loss: {loss:.4f}')    \n",
    "        \n",
    "# plot\n",
    "predicted = model(X).detach() # require_grad = False, to plot\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted, 'b')\n",
    "plt.title('DATA & LINEAR REGRESSION ESTIMATED')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"11\"></a> \n",
    "### 11)IMPLEMENTING LINEAR REGRESSION (REGRESSION)<br>\n",
    "\n",
    "\n",
    "[Ir a índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss: 0.4372\n",
      "epoch: 20, loss: 0.3824\n",
      "epoch: 30, loss: 0.3434\n",
      "epoch: 40, loss: 0.3140\n",
      "epoch: 50, loss: 0.2909\n",
      "epoch: 60, loss: 0.2723\n",
      "epoch: 70, loss: 0.2568\n",
      "epoch: 80, loss: 0.2437\n",
      "epoch: 90, loss: 0.2324\n",
      "epoch: 100, loss: 0.2226\n",
      "accuracty = 0.9123\n"
     ]
    }
   ],
   "source": [
    "# STEPS:\n",
    "# 0) prepare the data\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "n_samples, n_features = X.shape\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state=1234)\n",
    "\n",
    "#scaling features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "# transform to tensor X and y\n",
    "X_train_std = torch.tensor(X_train_std, dtype = torch.float32)\n",
    "X_test_std = torch.tensor(X_test_std, dtype = torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype = torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype = torch.float32)\n",
    "# reshaping our y vector, to be a column vector instead of a row vector\n",
    "y_train = y_train.view(-1, 1)\n",
    "y_test = y_test.view(-1, 1)\n",
    "# 1) model\n",
    "# f = w*x + b, sigmoid function at the end(activation function)\n",
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_predicted = torch.sigmoid(self.linear(x))\n",
    "        return y_predicted\n",
    "\n",
    "\n",
    "model = LogisticRegression(n_features)\n",
    "\n",
    "# 2) loss and optimizer\n",
    "criteria = nn.BCELoss() # Binary cross entropy loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-2)\n",
    "# 3) training loop\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # forward pass and loss\n",
    "    y_predicted = model(X_train_std)\n",
    "    loss = criteria(y_predicted, y_train)\n",
    "    \n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # update the weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss: {loss:.4f}')\n",
    "    \n",
    "# Evaluation\n",
    "# we dont want to track the graph for this part\n",
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test_std)\n",
    "    #transform the probability results to the two labels (0, 1)\n",
    "    y_predicted_classes = y_predicted.round()\n",
    "    accuracy = (y_predicted_classes == y_test).sum()/y_test.shape[0]\n",
    "    print(f'accuracty = {accuracy:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"12\"></a> \n",
    "### 12)DATASETS AND DATALOADERS CLASSES<br>\n",
    "\n",
    "\n",
    "[Ir a índice](#indice)\n",
    "#### *Vocabulary*\n",
    "* epoch = 1 forward and backward pass of **ALL** training samples\n",
    "\n",
    "* batch_size = number of training samples in one forward & backward pass\n",
    "\n",
    "* number of iterations = number of passes, each pass using 'batch_size' number of samples\n",
    "\n",
    "* e.g. 100 samples, batch_size = 20 --> 100/20 = 5 iterations for 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_samples: 178, n_iterations: 44\n",
      "epoch : 1/2, step: 5/44, inputs: torch.Size([4, 13])\n",
      "epoch : 1/2, step: 10/44, inputs: torch.Size([4, 13])\n",
      "epoch : 1/2, step: 15/44, inputs: torch.Size([4, 13])\n",
      "epoch : 1/2, step: 20/44, inputs: torch.Size([4, 13])\n",
      "epoch : 1/2, step: 25/44, inputs: torch.Size([4, 13])\n",
      "epoch : 1/2, step: 30/44, inputs: torch.Size([4, 13])\n",
      "epoch : 1/2, step: 35/44, inputs: torch.Size([4, 13])\n",
      "epoch : 1/2, step: 40/44, inputs: torch.Size([4, 13])\n",
      "epoch : 1/2, step: 45/44, inputs: torch.Size([2, 13])\n",
      "epoch : 2/2, step: 5/44, inputs: torch.Size([4, 13])\n",
      "epoch : 2/2, step: 10/44, inputs: torch.Size([4, 13])\n",
      "epoch : 2/2, step: 15/44, inputs: torch.Size([4, 13])\n",
      "epoch : 2/2, step: 20/44, inputs: torch.Size([4, 13])\n",
      "epoch : 2/2, step: 25/44, inputs: torch.Size([4, 13])\n",
      "epoch : 2/2, step: 30/44, inputs: torch.Size([4, 13])\n",
      "epoch : 2/2, step: 35/44, inputs: torch.Size([4, 13])\n",
      "epoch : 2/2, step: 40/44, inputs: torch.Size([4, 13])\n",
      "epoch : 2/2, step: 45/44, inputs: torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "class Winedataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "        xy = np.loadtxt('./intro_pytorch_wine.csv', delimiter=',', dtype = np.float32, skiprows=1)\n",
    "        self.x = torch.tensor(xy[:, 1:], dtype = torch.float32)\n",
    "        self.y = torch.tensor(xy[:, [0]], dtype = torch.float32) # n_samples, 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "dataset = Winedataset()\n",
    "\n",
    "#################### DATALOADER ####################\n",
    "\n",
    "dataloader = DataLoader(dataset = dataset, batch_size= 4, shuffle= True)\n",
    "\n",
    "# training loop\n",
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = round(total_samples/4) # batch_size = 4\n",
    "\n",
    "print(f'total_samples: {total_samples}, n_iterations: {n_iterations}')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader): # i will give us the index\n",
    "        if (i + 1) % 5 == 0:\n",
    "            print(f'epoch : {epoch + 1}/{num_epochs}, step: {i + 1}/{n_iterations}, inputs: {inputs.shape}')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2340e+01, 2.4500e+00, 2.4600e+00, 2.1000e+01, 9.8000e+01, 2.5600e+00,\n",
      "         2.1100e+00, 3.4000e-01, 1.3100e+00, 2.8000e+00, 8.0000e-01, 3.3800e+00,\n",
      "         4.3800e+02],\n",
      "        [1.2820e+01, 3.3700e+00, 2.3000e+00, 1.9500e+01, 8.8000e+01, 1.4800e+00,\n",
      "         6.6000e-01, 4.0000e-01, 9.7000e-01, 1.0260e+01, 7.2000e-01, 1.7500e+00,\n",
      "         6.8500e+02],\n",
      "        [1.2840e+01, 2.9600e+00, 2.6100e+00, 2.4000e+01, 1.0100e+02, 2.3200e+00,\n",
      "         6.0000e-01, 5.3000e-01, 8.1000e-01, 4.9200e+00, 8.9000e-01, 2.1500e+00,\n",
      "         5.9000e+02],\n",
      "        [1.2210e+01, 1.1900e+00, 1.7500e+00, 1.6800e+01, 1.5100e+02, 1.8500e+00,\n",
      "         1.2800e+00, 1.4000e-01, 2.5000e+00, 2.8500e+00, 1.2800e+00, 3.0700e+00,\n",
      "         7.1800e+02]]) tensor([[2.],\n",
      "        [3.],\n",
      "        [3.],\n",
      "        [2.]])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "cont = 0\n",
    "for X,y in dataloader:\n",
    "    print(X, y)\n",
    "    cont+=1\n",
    "    print(cont)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"13\"></a> \n",
    "### 13)DATASETS AND DATALOADERS CLASSES<br>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch library, has the module `torchvision` with transforms which can be applied to PIL images, tensors, ndarrays, or custom data during creation of the Dataset:    \n",
    "* On Images:\n",
    "        CenterCrop, Greyscale, Pad, RandomAffine, RandomCrop, RandomHorizontalFlip, RandomRotation, Resize, Scale.\n",
    "* On Tensors:\n",
    "        LinearTransformation, Normalize, RandomErasing\n",
    "        \n",
    "* Conversion:\n",
    "        ToPILImage: from tensor or ndarray\n",
    "        ToTensor: from numpy.ndarray or PILImage\n",
    "* Generic:\n",
    "        Use Lambda\n",
    "* Custom:\n",
    "        Write own class\n",
    "* Compose multiple Transforms:\n",
    "\n",
    "        composed = transforms.Compose([Rescale(256), RandomCrop(224)])\n",
    "        torchvision.transforms.ReScale(256)\n",
    "        torchvision.transforms.ToTensor()\n",
    "\n",
    "[Ir a índice](#indice)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "\n",
      " Here we see how the tensor its multuplicated by the factor : 2\n",
      " tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
      "        6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
      "        2.1300e+03])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Doing differents transform from scratch\n",
    "\n",
    "class Winedataset(Dataset):\n",
    "    \n",
    "    def __init__(self, transform = None):\n",
    "        # data loading\n",
    "        xy = np.loadtxt('./intro_pytorch_wine.csv', delimiter=',', dtype = np.float32, skiprows=1)\n",
    "        # Note that we do not convert to tensor here.\n",
    "        self.x = xy[:, 1:]\n",
    "        self.y = xy[:, [0]] # n_samples, 1\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "       \n",
    "######################### Custom Transformation by scratch #########################\n",
    "class ToTensor():\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.tensor(inputs), torch.tensor(targets)\n",
    "\n",
    "class MulTransform(): # multiplication transform, recives factor (the number which will use to multiplicate)\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        input, target = sample\n",
    "        input *= self.factor\n",
    "        return input, target\n",
    "    \n",
    "    \n",
    "dataset = Winedataset(transform = None)\n",
    "\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features), type(labels))\n",
    "\n",
    "composed = torchvision.transforms.Compose([ToTensor(),\n",
    "                                           MulTransform(factor = 2)])\n",
    "\n",
    "dataset = Winedataset(transform = composed)\n",
    "\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(f'\\n Here we see how the tensor its multuplicated by the factor : {2}\\n {features}')\n",
    "print(type(features), type(labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"14\"></a> \n",
    "### 14)SOFTMAX AND CROSS-ENTROPY<br>\n",
    "\n",
    "[Ir a índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax numpy: [0.65900114 0.24243297 0.09856589]\n",
      "softmax numpy (with tensors): tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "# Softmax function from scratch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x), axis = 0)\n",
    "\n",
    "x = np.array([2.0, 1.0, 0.1])\n",
    "outputs = softmax(x)\n",
    "print(f'softmax numpy: {outputs}')\n",
    "\n",
    "\n",
    "x = torch.tensor([2.0, 1.0, 0.1])\n",
    "outputs = torch.softmax(x, dim = -1) # automatically find the correct dimension 'dim = -1'\n",
    "print(f'softmax numpy (with tensors): {outputs}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we applied a softmax function and after we want to calculate the Cross - Entropy, to find how well our **CLASIFICATION MODEL** performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss1 numpy:0.3567\n",
      "Loss2 numpy:2.3026\n"
     ]
    }
   ],
   "source": [
    "# Cross-entropy from scratch\n",
    "def cross_entropy(actual, predicted):\n",
    "    loss = -np.sum(actual * np.log(predicted))\n",
    "    return loss # if we want to normalice it '/float(predicted.shape[0])'\n",
    "\n",
    "# y must be one hot encoded\n",
    "# if class 0: [1 0 0]\n",
    "# if class 1: [0 1 0]\n",
    "# if class 2: [0 0 1]\n",
    "\n",
    "Y = np.array([1, 0, 0])\n",
    "\n",
    "# y_pred has probabilities\n",
    "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
    "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
    "l1 = cross_entropy(Y, Y_pred_good)\n",
    "l2 = cross_entropy(Y, Y_pred_bad)\n",
    "print(f'Loss1 numpy:{l1:.4f}')\n",
    "print(f'Loss2 numpy:{l2:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **nn.CrossEntropyLoss**<br>\n",
    "#### This function applies nn.LogSoftmax + nn.NLLLoss(negative log likelihood loss)\n",
    "\n",
    "## `No need a Softmax in the last layer!`\n",
    "\n",
    "*   Y has class labels, not One-Hot!\n",
    "*   Y_pred has raw scores (logits), no Softmax!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss1 pred_good: 0.3002\n",
      "Loss2 pred_bad:  1.6242\n",
      "tensor([2, 0, 1])\n",
      "tensor([0, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# 3 samples\n",
    "Y = torch.tensor([2, 0, 1]) #Y_true (not one hot encoded)\n",
    "# nsamples x nclasses = 3x3\n",
    "Y_pred_good = torch.tensor([[0.1, 1.0, 2.1], [2.0, 1.0, 0.1], [0.0, 3.0, 0.1]])\n",
    "Y_pred_bad = torch.tensor([ [2.1, 1.0, 0.1], [0.1, 1.0, 2.1], [0.1, 3.0, 0.1]])\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "\n",
    "\n",
    "print(f'Loss1 pred_good: {l1.item():.4f}')\n",
    "print(f'Loss2 pred_bad:  {l2.item():.4f}')\n",
    "\n",
    "################### PREDICTIONS ###################\n",
    "\n",
    "_, predictions1 = torch.max(Y_pred_good, dim = 1) #in '_' we save the value of the tensor, which we dont need\n",
    "_, predictions2 = torch.max(Y_pred_bad,  dim = 1)\n",
    "\n",
    "print(predictions1)\n",
    "print(predictions2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"15\"></a> \n",
    "### BINARY CLASS CLASSIFICATION PROBLEMS\n",
    "\n",
    "Here we have to use `nn.BCELoss()` Sigmoid at the end, where we set a threshold (i.e. 0 = not dog, 1 = dog)\n",
    "\n",
    "[Ir a índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#Binary classification\n",
    "class NeuralNet1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet1, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1) # 1 label of output (dog or not dog), so output_size = 1\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        \n",
    "        # sigmoid at the end\n",
    "        y_pred = torch.sigmoid(out) # SIGMOID FUNCTION\n",
    "        return y_pred\n",
    "    \n",
    "model = NeuralNet1(input_size = 28*28, hidden_size = 5)\n",
    "criterion = nn.BCELoss()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"16\"></a> \n",
    "### MULTI CLASS CLASSIFICATION PROBLEMS<br>\n",
    "* Neural Net with Softmax (which animal?)\n",
    "\n",
    "Here we have to use `nn.CrossEntropyLoss()` Sigmoid at the end, where we set a threshold (i.e. 0 = not dog, 1 = dog)\n",
    "\n",
    "[Ir a índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "# Multiclass problem\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes) # the last layer, the output size is equal to the \n",
    "                                                           # number of classes, each class has it's own output\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        # no softmax at the end\n",
    "        return out\n",
    "    \n",
    "model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
    "criterion = nn.CrossEntropyLoss() #(applies Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Create our functions from nn modules\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "# FIRST WE DEFINE ALL THE LAYERS THAT WE WANT\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "# CALL THE FUCTIONS ONE AFTER ANOTHER\n",
    "        out = F.linear1(x) # out = self.linear1(x)\n",
    "        out = F.relu(out) # self.relu(out)\n",
    "        out = F.linear2(out)# ...\n",
    "        out = F.sigmoid(out)# ...\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"17\"></a> \n",
    "### FEED FORWARD NETWORKS<br>\n",
    "\n",
    "Using all the previous steps to train a nn<br>\n",
    "[Ir a índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/2, step: 100/600, loss: 0.4575\n",
      "epoch: 1/2, step: 200/600, loss: 0.3064\n",
      "epoch: 1/2, step: 300/600, loss: 0.5675\n",
      "epoch: 1/2, step: 400/600, loss: 0.1916\n",
      "epoch: 1/2, step: 500/600, loss: 0.1967\n",
      "epoch: 1/2, step: 600/600, loss: 0.3065\n",
      "epoch: 2/2, step: 100/600, loss: 0.2409\n",
      "epoch: 2/2, step: 200/600, loss: 0.0832\n",
      "epoch: 2/2, step: 300/600, loss: 0.1951\n",
      "epoch: 2/2, step: 400/600, loss: 0.1976\n",
      "epoch: 2/2, step: 500/600, loss: 0.1945\n",
      "epoch: 2/2, step: 600/600, loss: 0.1917\n",
      "Accuracy: 95.72\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # if we have GPU we will use it, if not, we use cpu.\n",
    "\n",
    "# hyper parameters\n",
    "input_size = 784 # our inputs from MNIST have a resolution of 28x28=784 if we flatten it.\n",
    "hidden_size = 100 \n",
    "num_classes = 10 # digits from 0-9\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root = './intro_pytorch_data', train = True, transform = transforms.ToTensor(), download = True)\n",
    "test_dataset = torchvision.datasets.MNIST(root = './intro_pytorch_data', train = False, transform = transforms.ToTensor(), download = False)\n",
    "\n",
    "# DataLoader, Transformation\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# # testing the first batch of our dataloader 'torch.Size([100, 1, 28, 28])' 100 its the size of the batch, channels, width, height\n",
    "# for i, (samples, labels) in enumerate(train_dataloader):\n",
    "#     if i == 0:\n",
    "#      print(samples.shape, labels.shape)   \n",
    "#      break\n",
    "# ##Plotting the data of training##\n",
    "# for i in range(6):\n",
    "#     plt.subplot(2, 3, i+1)\n",
    "#     plt.imshow(samples[i][0],cmap = 'gray')\n",
    "# plt.show()\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # now we create our layers\n",
    "        self.l1 = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
    "        # self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(in_features=hidden_size, out_features=num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out\n",
    "        # note: we do not use the softmax activation function at the exit of l2 because \n",
    "        # we use CrossEntropyLoss which already has the softmax applied at the exit.\n",
    "        \n",
    "        \n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# define the loss function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "# Training Loop (batch training) \n",
    "number_total_steps = len(train_dataloader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(X_train, y_train) in enumerate(train_dataloader):\n",
    "        # we have to reshape the data from 100, 1, 28, 28 to 100, 784(100 = num of batches, 784 = number of inputs)\n",
    "        X_train = X_train.view(-1, 28*28).to(device) # we reshape and then send the data to GPU\n",
    "        y_train = y_train.to(device) # send the data to GPU\n",
    "        \n",
    "        # Forward Pass\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        \n",
    "        # Clean the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Backward Pass\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'epoch: {epoch+1}/{num_epochs}, step: {i+1}/{number_total_steps}, loss: {loss.item():.4f}')\n",
    "\n",
    "# Testing\n",
    "with torch.no_grad():\n",
    "    n_correct_predictions = 0\n",
    "    n_samples = 0\n",
    "    for X_test, y_test in test_dataloader:\n",
    "        # we have to reshape the data from 100, 1, 28, 28 to 100, 784(100 = num of batches, 784 = number of inputs)\n",
    "        X_test = X_test.view(-1, 28*28).to(device) # we reshape and then send the data to GPU\n",
    "        y_test = y_test.to(device) # send the data to GPU    \n",
    "        outputs = model(X_test)\n",
    "        \n",
    "        #return value, index = _, predictions\n",
    "        _, predictions = torch.max(outputs, dim = 1)\n",
    "        n_samples +=y_test.shape[0]\n",
    "        n_correct_predictions += (predictions == y_test).sum()\n",
    "    \n",
    "    accuracy = 100.0 * n_correct_predictions / n_samples\n",
    "    print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"18\"></a> \n",
    "### CONVOLUTIONAL NEURAL NET (CNN)<br>\n",
    "\n",
    "Building a CNN with CIFAR-10<br>\n",
    "[Ir a índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "# device = torch.device('mps')\n",
    "# Hyper parameters\n",
    "num_epochs = 10\n",
    "batch_size = 4\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# dataset has PILImage images of range [0. 1]\n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root = './intro_pytorch_data', train = True, download= True, transform= transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root = './intro_pytorch_data', train = False, download= True, transform= transform)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Implement the Conv net\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.pool(F.relu(self.conv1(x)))\n",
    "        out = self.pool(F.relu(self.conv2(out)))\n",
    "        out = out.view(-1, 16*5*5) #flatten\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model_cnn = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_cnn.parameters(), lr = learning_rate)\n",
    "\n",
    "n_total_steps = len(train_dataloader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(X_train, y_train) in enumerate(train_dataloader):\n",
    "        # origin shape :[4, 3, 32, 32] = 4, 3, 1024\n",
    "        # input_layer : 3 input channels, 6 output channels, 5 kernel size\n",
    "        X_train = X_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "        \n",
    "        # Forward pass and loss\n",
    "        predictions = model_cnn(X_train)\n",
    "        loss = criterion(predictions, y_train)\n",
    "        # Clean gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Backward Pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if(i + 1) % 6250 == 0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Step: {i+1}/{n_total_steps}, Loss: {loss.item():.4f}')\n",
    "print(\"Finished Training\")\n",
    "            \n",
    "            \n",
    "# Testing\n",
    "with torch.no_grad(): # because we dont need the .backward()\n",
    "    n_corrects = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for X_test, y_test in test_dataloader:\n",
    "        y_test = y_test.to(device)\n",
    "        X_test = X_test.to(device)\n",
    "        outputs = model_cnn(X_test)\n",
    "        # max returns (value, index)\n",
    "        _, y_pred = torch.max(model_cnn(X_test), dim = 1)\n",
    "        n_samples += y_test.size(0)\n",
    "        n_corrects += (y_pred == y_test).sum()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            label = y_test[i]\n",
    "            y_predicted = y_pred[i]\n",
    "            if(label == y_predicted):\n",
    "                n_class_correct[label]+=1\n",
    "            n_class_samples[label]+=1\n",
    "    accuracy = 100.0 * n_corrects / n_samples\n",
    "    print(f'Accuracy of the cnn: {accuracy}%')\n",
    "    \n",
    "    for i in range(10):\n",
    "        accuracy = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {accuracy}%')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"19\"></a> \n",
    "### TENSORBOARD WITH PYTORCH<br>\n",
    "\n",
    "Using tensorboard in the FEEDFORWARD NET that we create before<br>\n",
    "[Ir a índice](#indice)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To launch tensorboard in our program, we have to execute it first and then open the prompt terminal and go to the directory where our program is, and write.. (2 options):<br>\n",
    "\n",
    "* `tensorboard --logdir=runs`\n",
    "* `tensorboard --logdir=data/ --host localhost --port 8088` and navigated the browser to http://localhost:8088\n",
    "\n",
    "note: we have to had installed tensorboard (pip install tensorboard) in our enviorment\n",
    "\n",
    "To launch tensorboard with pytorch we need to :\n",
    "* from torch.utils.tensorboard import SummaryWriter\n",
    "* writer = SummaryWriter(\"runs/mnist\") [\"runs/mnist\" is the default directory where will save the logfiles] // This will print in the tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "epoch: 1/2, step: 100/600, loss: 0.3541\n",
      "epoch: 1/2, step: 200/600, loss: 0.3507\n",
      "epoch: 1/2, step: 300/600, loss: 0.3879\n",
      "epoch: 1/2, step: 400/600, loss: 0.3483\n",
      "epoch: 1/2, step: 500/600, loss: 0.2650\n",
      "epoch: 1/2, step: 600/600, loss: 0.4211\n",
      "epoch: 2/2, step: 100/600, loss: 0.1659\n",
      "epoch: 2/2, step: 200/600, loss: 0.1031\n",
      "epoch: 2/2, step: 300/600, loss: 0.1983\n",
      "epoch: 2/2, step: 400/600, loss: 0.1841\n",
      "epoch: 2/2, step: 500/600, loss: 0.1412\n",
      "epoch: 2/2, step: 600/600, loss: 0.1790\n",
      "Accuracy: 95.42\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD6CAYAAAC4RRw1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAcdElEQVR4nO3de5BUxdkG8OdluWiCQS4fZBFkoxJuhoqGIiDGS6xNgUqQhGuMrJGAGAkXiQpiqUEjRgskUYxuCgowBEgEgUoq6kLWSzQhspYgdxAUMAsIJAIKsgv9/bHHpvuwMzs7c+ac6TPPr2pr356emfPCuzRne/r0EaUUiIjIPQ2iToCIiNLDAZyIyFEcwImIHMUBnIjIURzAiYgcxQGciMhRGQ3gItJXRLaKyA4RmRxUUhQt1jW+WNt4kXTXgYtIAYBtAIoB7AXwNoDhSqlNwaVHYWNd44u1jZ+GGby2J4AdSqmdACAiiwEMAJDwh0FEeNVQjlBKSYIu1tVtB5VS/5egr161ZV1zSq11zWQK5QIAe4z2Xu8xi4iMFpG1IrI2g2NReFhXt32YpK/O2rKuOavWumZyBl7bGdxZ/2MrpUoBlAL8H90RrGt81Vlb1tUtmZyB7wXQ3mi3A/CfzNKhHMC6xhdrGzOZDOBvA+goIl8TkcYAhgFYGUxaFCHWNb5Y25hJewpFKVUtImMBvAygAMBcpdTGwDKjSLCu8cXaxk/aywjTOhjn1HJGklUo9ca65pQKpVSPIN6Idc0ptdaVV2ISETmKAzgRkaM4gBMROYoDOBGRoziAExE5igM4EZGjMrmU3mlFRUVWu1+/fgmfO3PmTB03adIk6fveeeedOt63b5/V9+KLL9YjQyJKxYIFC6z2f//7Xx3/9a9/tfpeeeWVUHIKC8/AiYgcxQGciMhRHMCJiBwV6znwhg3tP96DDz6o45tvvtnq69ChQ0rvWdfWA7Nnz9bxp59+avUNGTJEx3/7299SOh5lpkGDM+coP/rRj6y+6667Tse33npr0vfZsWOHjhcvXmz1PfPMMzqurKxMJ03KQO/eva32xRdfrONjx45ZfZwDJyKinMABnIjIUbGbQuncubOOp02bZvX98Ic/TPg6c7rjhRdesPrKyspSPv6cOXN0/KUvfcnqu+uuu3RcXl5u9Z04cSLlY1BiLVu2tNqPPvqojkeNGmX1nT59WsdHjx61+goKCqy2+Wv51KlTrT7z58q/HHXPnjN3MDOPR8HxLxUcN26cjps3bx52OqHiGTgRkaM4gBMROYoDOBGRo2I3B96qVSsdJ5vz9hs6dKiOM1nid/755+v46aeftvr69Omj46uvvtrqe/nll9M+Jp1x6NAhq718+XIdb9q0yeoztzpYsmSJ1XfhhRda7YEDB+r4pz/9qdVnfu6ya9cuq69Lly463rp1a7LUKU3r1q1L2DdmzBir7f9czL/dhWt4Bk5E5CgO4EREjordTY27deum45deesnqa9u2bcLX3XjjjTrOZArl8OHDOm7WrJnV98knn+i4RYsWaR8jCLypsV0D/y6TJ0+etNr+qRnTE088oeNJkyZZfYsWLdLxiBEjrL5Tp06lnmzq8u6mxv6lm+a0WaNGjaw+/xLQ6dOnZy2vgPGmxkREccIBnIjIURzAiYgcFbtlhBs3btRx//79rb7CwsKEr6uoqEjp/Rs3bmy1J06caLXNZYT+zxfMnQopHGa9xo8fb/X9/Oc/13G7du2svlWrVlnt733vewmP8frrryc8xvDhw3XsX8LGZYXB8H9mZX4O1aZNG6vvkksuCSWnsPAMnIjIUXUO4CIyV0QOiMgG47EWIlImItu97/HeMSaGWNf4Ym3zR53LCEXkKgDHACxQSl3qPfY4gMNKqcdEZDKA5kqpe+s8mCPLkpK59NJLrbb/KjCRM6vz/H+3P/7xj3VsLi+LyNXIg7qay8YefvjhlF9XnykU07/+9S+r3bNnTx3/7ne/s/rMG2AHqALAXQigtrlc12TMm2r4p1D8N1k577zzQskpAOktI1RKvQ7gsO/hAQDme/F8ADdlmh2Fi3WNL9Y2f6Q7B95GKVUJAN731sGlRBFiXeOLtY2hrK9CEZHRAEZn+zgULtY1nlhXt6Q7gO8XkUKlVKWIFAI4kOiJSqlSAKWAu3NqRUVFOn7++eeTPtecA//Nb35j9fnv9JODnKyruVSwV69eVt/o0YnHog8//FDHQd0tx7zBMWDPgUcspdrmUl2pbulOoawEUOLFJQBWBJMORYx1jS/WNoZSWUa4CMA/AXQSkb0iMhLAYwCKRWQ7gGKvTQ5hXeOLtc0fdU6hKKWGJ+i6LuBcctbSpUt13L1796TPffHFF3V8//33W31VVVXBJpaBONXV3GXy1VdfTfi8N99802oPHjxYx9XV1VZfp06dgkkuAnGqLSXHKzGJiBzFAZyIyFEcwImIHBW73Qiz4aKLLkr5ubNmzdKx/7JdCoZ/R8hx48YlfO6vf/1rHfuXdSa7oe3BgwfTzI4oPDwDJyJyFAdwIiJHcQrFc8MNN+jY3OgfsG/S4L+57Q9+8AOrbW7uT9lx+eWXW+0JEybo+Pjx41bfK6+8ouNkUyYUH6+99pqOhw4davU1aBCvc9Z4/WmIiPIIB3AiIkdxACcichTnwD1jxozRcXFxsdVn7lTnv1Sbc97hGzFiRMI+fz3Ky8uznY4l2ZLTnTt3hphJ/nrrrbd0PGTIEKuvUaNGVvvqq6/WsTl37gqegRMROYoDOBGRoziAExE5Kq/mwM855xwd9+hh3+D5m9/8ZsLXrV69Wsd33HFH4HlRZsy1348//njoxze3sx01alTC5y1cuDCMdPLeqlWrdPz5559bfeYYANjbQ3MOnIiIQsMBnIjIUXk1hTJx4kQdP/LIIym/btCgQTo+cuRIoDlRasztDMx6AMCBA2fuzxv2skEAuOqqq3RcWFho9S1fvlzH/m0YKDs2bdqkY/+dlvwGDhyo46eeeiprOWULz8CJiBzFAZyIyFEcwImIHBXrOfArrrjCat99990Jn/vZZ5/p2NyeFACOHTsWaF5UfwUFBTpu1aqV1Rf2nY/atWtnte+5556Ez/3Vr36l46qqqqzlRLVbsmSJ1R45cqTV7ty5c5jpBI5n4EREjuIATkTkqNhNoXTr1k3H/l+fmjVrlvB106ZN0/GcOXOCT8zHn8vTTz+tY3PJnJ//StC9e/cGmhfVbd68eVbbvIrXv+PgBx98kP2EKKH3338/6hSyimfgRESO4gBOROSoOgdwEWkvIuUisllENorIeO/xFiJSJiLbve/Ns58uBYV1ja1GrGv+SGUOvBrAJKXUOyJyHoAKESkDcCuA1Uqpx0RkMoDJAO7NXqqpad78zM+luUuc35YtW6z2smXLspbTF4YNG6bj22+/3eozL8dOZvr06Vb7lltuSTcdp+oatWuvvVbH3/nOdxI+z38X9Igun2ddU2QuSR0wYIDVt2LFirDTqbc6z8CVUpVKqXe8+CiAzQAuADAAwHzvafMB3JSlHCkLWNfYqmJd80e9VqGISBGAywCsAdBGKVUJ1AwGItI6wWtGAxidYZ6URaxrPLGu8ZfyAC4iTQEsBTBBKXVERFJ6nVKqFECp9x4qnSSz4cSJE1a7Z8+eOu7Vq1fC15k3OK6NeZNU/6/T5557ro79N1c1+adzzKvHgr6az5W6mvXauHGj1WfuANipUyerb+vWrWkdz6wjACxdulTH/tqZv2qvW7cureMFzZW6Rq1hwzNDoDn96oqUVqGISCPU/DAsVEp9MbrsF5FCr78QwIFEr6fcxLrGE+uaP1JZhSIA5gDYrJSaaXStBFDixSUAcn/GnzTWNdZY1zyRyhRKHwC3AHhPRN71HrsPwGMA/iQiIwHsBjA4KxlStrCu8dQUrGveqHMAV0r9A0CiCbTrgk0nc+auguadOQCga9euOvbfxPgPf/hDIMc35xq3bdtm9fnn3U3333+/jt98802rLxt3AXKtruaOg2+88YbVN2bMGB2vXbvW6jO3KJgyZYrVZ86d+3cU9O9a17RpUx0/8MADVt+sWbN0XNcdYEJwTCnlTF2zraKiIuoUsopXYhIROYoDOBGRo0Sp8FYKhb0sqUmTJlZ70aJFOvZfdZWqjz76yGo/+uijVtucQvHvhnj48OG0jpkNSX7Nrreo61pSUqLjZ5991uozl30eP37c6jNvEnHOOeckPeaDDz6oY3/NT506VUfGoapQSvUI4o3iuIzQvIkxYC8Pve2226w+/66TEau1rjwDJyJyFAdwIiJHcQAnInJUrOfAKTGX58BrOb6O27RpY/WVlZXp2Lxbk9/u3but9kMPPWS1FyxYoOO6tlOIGOfA44lz4EREccIBnIjIUbG7qTHlH3MacN++fVbfN77xjbDTIQoNz8CJiBzFAZyIyFEcwImIHMUBnIjIURzAiYgcxQGciMhRHMCJiBzFAZyIyFEcwImIHMUBnIjIUWFfSn8QwIcAWnlxLsjHXDoE/H6sa3Jh5hJkbVnX5CKva6jbyeqDiqwNasvLTDGX4ORS/swlOLmUP3OxcQqFiMhRHMCJiBwV1QBeGtFxa8NcgpNL+TOX4ORS/szFEMkcOBERZY5TKEREjuIATkTkqFAHcBHpKyJbRWSHiEwO89je8eeKyAER2WA81kJEykRku/e9eQh5tBeRchHZLCIbRWR8VLkEgXW1colNbVlXK5ecrGtoA7iIFACYDaAfgK4AhotI17CO75kHoK/vsckAViulOgJY7bWzrRrAJKVUFwC9ANzp/V1EkUtGWNezxKK2rOtZcrOuSqlQvgD0BvCy0Z4CYEpYxzeOWwRgg9HeCqDQiwsBbI0gpxUAinMhF9aVtWVd3alrmFMoFwDYY7T3eo9FrY1SqhIAvO+twzy4iBQBuAzAmqhzSRPrmoDjtWVdE8iluoY5gEstj+X1GkYRaQpgKYAJSqkjUeeTJta1FjGoLetai1yra5gD+F4A7Y12OwD/CfH4iewXkUIA8L4fCOOgItIINT8IC5VSy6LMJUOsq09Masu6+uRiXcMcwN8G0FFEviYijQEMA7AyxOMnshJAiReXoGZuK6tERADMAbBZKTUzylwCwLoaYlRb1tWQs3UNeeL/egDbALwPYGoEHzwsAlAJoAo1ZxgjAbREzafH273vLULI40rU/Dq6HsC73tf1UeTCurK2rKu7deWl9EREjuKVmEREjuIATkTkqIwG8KgvtaXsYF3ji7WNmQwm9QtQ8+HGRQAaA1gHoGsdr1H8yo0v1jW2Xx8HVdsc+LPwq466ZnIG3hPADqXUTqXUSQCLAQzI4P0oN7CubvswSR9r665a65rJAJ7SpbYiMlpE1orI2gyOReFhXeOrztqyrm5pmMFrU7rUVilVCu/WQyJyVj/lHNY1vuqsLevqlkzOwHP1UlvKDOsaX6xtzGQygOfqpbaUGdY1vljbmEl7CkUpVS0iYwG8jJpPt+cqpTYGlhlFgnWNL9Y2fkK9lJ5zarlDKVXbfGhaWNecUqGU6hHEG7GuOaXWuvJKTCIiR3EAJyJyFAdwIiJHcQAnInIUB3AiIkdxACcichQHcCIiR3EAJyJyFAdwIiJHcQAnInJUJtvJEjmtadOmOt6/f7/Vd+ONN1rt8vLyUHIiqg+egRMROYoDOBGRo/J2N8JGjRpZ7QYNgv+/7PTp0wnbDRsmnr06efKk1c5GjbgbIdC4cWMdr1mzxur73//+Z7WvvfbaMFIKQt7vRmj+27744outvptvvtlqP/fcczpu3bq11Tdz5kwd33TTTVaf/+cjBNyNkIgoTjiAExE5igM4EZGjnFhGKGJP15rLv84991yr76677krpPb///e9b7U6dOqWZXWJbtmyx2jt37tTx9ddfn/B1w4YNs9p//vOfg02MANifNdx9991W35NPPmm1zc8sqqurs5sY1amgoEDHI0eOtPqmTJmi43bt2ll969evt9pFRUU69s+Pm77yla9Y7QjmwGvFM3AiIkdxACcicpQTUyiDBw+22osWLYook7qZv5Z37NjR6uvcuXNK79G9e3erzSmU7NuzZ4/VvvTSS612kyZNdMwplPDdeuutVru4uFjHw4cPt/qOHj2q4xUrVlh9gwYNstoDBw7UcbIplFzFM3AiIkdxACcichQHcCIiRzkxB75kyRKr7b9EPVXm0p+FCxdafZs3b07rPf127dql4yeeeMLq69q1a8LXffbZZzqeMWNGILkQucy8DH7q1KlWX4cOHXTsX/Jptvfu3Zv0GP369cskxcjxDJyIyFF1DuAiMldEDojIBuOxFiJSJiLbve/Ns5smBY11jS/WNn+kMoUyD8DTABYYj00GsFop9ZiITPba9wafXo3nn3/eavfv31/H/iukkikrK9PxL37xC6vPvNLOnM6oL3PXurZt26b8OnOpZEhXec1DxHWlrJkHB2vbqlUrq/3SSy/p2L+roHmDjUmTJqV9zB49Em/c+Omnn+r41KlTaR8jm+o8A1dKvQ7gsO/hAQDme/F8ADcFmxZlG+saX6xt/kj3Q8w2SqlKAFBKVYpI60RPFJHRAEaneRwKF+saXynVlnV1S9ZXoSilSgGUAu5uEE9nY13jiXV1S7oD+H4RKfT+Jy8EcCDIpPxGjBhhtS+//HIdT5gwweozb0bbrFkzq69v37469l+eft555+n44YcftvrM+bYvf/nLVt9VV11ltc35+vPPP9/q++CDD3Rs3u0DAF577TXkgFDrSqHK+dpeeOGFVtuc9/bvIviTn/wkrWOYO5kC9hYJfsuWLdPxRx99lNbxsi3dZYQrAZR4cQmAFUmeS+5gXeOLtY2hVJYRLgLwTwCdRGSviIwE8BiAYhHZDqDYa5NDWNf4Ym3zR51TKEqp4Qm6rgs4l5S98847OvZPr3zrW9/S8fjx462+nj176ticavHz70S3evVqHX/1q1+1+vxTKEeOHNHxuHHjrL4FC86s6jJ3TItCLtaVguFqbX/2s58l7Js+fbrV3r17d0rv6Z8y+f3vf2+1u3TpkvC15hRKruKVmEREjuIATkTkKA7gRESOcmI3wvqoqKjQsX9+3JwPmz17ttVnXp7fsmVLq2/IkCEpH/+OO+7Q8eLFi1N+HUXLXGIKAG+88YbVzmR7BUpNZWVl4O/Zu3dvqz106NCUX7tx48ag0wkcz8CJiBzFAZyIyFGxm0JJ5tixYzouKSmx+swlQwMGDEj7GOZSKHM3M8DeDfHEiRNpH4OCZ+5GCZy9+5xSvKo82+bMmWO1zZs4+K+8NP8tHT5s79tl3jgl2TJBv0OHDlntzz//POXXRoVn4EREjuIATkTkKA7gRESOyqs58CCsW7fOahcUFFjtPn361BoDwHPPPafjWbNmWX3btm0LKENKR7IbTlM49u/fb7Xnzp2r49tuu83q+/vf/67jjz/+2Oozdytt3jz1O8etWrXKau/Zsyfl10aFZ+BERI7iAE5E5CgO4EREjuIceArMeW/zrvPA2XPgTz75pI4HDhxo9d1+++069q81Hzt2rI7/8pe/WH1VVVX1zJhSISI6/vrXv271rVmzJux08t7x48ettrkds3/75W7duun4sssus/rMupaWllp9u3btstr+bWpdwzNwIiJHcQAnInIUp1BSYE5pfPLJJ0mfa16iP2PGDKvv29/+to79NzV+4YUXdPzMM89YfebOiVu2bEkhY0qFeYPqK6+80upz4W4scWfuADlx4sSEz+vcubPVbtDgzHnppk2brL4bbrghoOxyA8/AiYgcxQGciMhRHMCJiBzFOXCPObfsX+JnLgf87W9/a/UdPHgw4XuuX78+Yfutt96y+u655x4djxo1yuobNGiQjouLi62+DRs2JDw+pa+8vDzqFChF+fy5EM/AiYgcxQGciMhRnELxmMv47r33XqvP3KnOnM4AgGeffTat4/lvmGouPzR3WgPsq8keeughq8+fD6XnyJEjVnvfvn0RZULZNGbMmKhTCBTPwImIHFXnAC4i7UWkXEQ2i8hGERnvPd5CRMpEZLv3PfWNdylyrGtsNWJd80cqZ+DVACYppboA6AXgThHpCmAygNVKqY4AVnttcgfrGl+sa56ocw5cKVUJoNKLj4rIZgAXABgA4BrvafMBvArg3lreIlb8OwymOweezPz58632U089peNLLrkkkGOwrjb/nLfDc+BVSql3ANa1Nq1atYo6hUDV60NMESkCcBmANQDaeIMAlFKVItI6wWtGAxidYZ6URaxrPLGu8ZfyAC4iTQEsBTBBKXXE3HM3GaVUKYBS7z1UOklS9rCu8cS65oeUBnARaYSaH4aFSqkvtmnbLyKF3v/mhQAOZCvJMJhXNJo3ZQDsndD8u9aVlZVZ7eHDh+s42VWafuZSxSuuuMLqa9jwTJl++ctfpvyedcmHuuYj1jV/pLIKRQDMAbBZKWXugboSwBeLl0sArAg+PcoW1jXWWNc8kcoZeB8AtwB4T0Te9R67D8BjAP4kIiMB7AYwOCsZUrawrvHUFKxr3khlFco/ACSaQLsu2HQoLKxrbB1TSrGueYKX0ntOnjyp4/vuu8/qMz8AmjBhgtX33e9+12qbdwAx76QDAAcOJJ52NI/Ztm1bq898n+XLlyd8DyKytW/f3mq3adPGaqf64W6u4qX0RESO4gBOROQoTqHUwpxOAYDJk89cdfzHP/7R6ps6darVNm8G8cADDwSSz7Rp03SsFJfmBqV79+5Rp0BZ5r/hcVFRkdU2/z39+9//DiOlQPEMnIjIURzAiYgcxQGciMhRnANPQVVVlY4rKiqsviFDhljtsWPH6viaa66x+vr3769j/y6G5h1hZsyYYfUdOnSofglTSsybTL/33nsRZkLZ4r859dq1a612jx49dHzs2LFQcgoSz8CJiBzFAZyIyFES5rK0fNueskED+//HgoICHVdXV1t9YS8PTHK5db3lW11zXIVSqkfdT6tbHOvqX1ZoTrE88sgjVp//SuqI1VpXnoETETmKAzgRkaM4gBMROYrLCLPo9OnTSdtEFK4tW7ZY7cLCwogyCQbPwImIHMUBnIjIURzAiYgcxQGciMhRHMCJiBzFAZyIyFFhLyM8COBDAK28OBfkYy4dAn4/1jW5MHMJsrasa3KR1zXUvVD0QUXWBrVfQ6aYS3ByKX/mEpxcyp+52DiFQkTkKA7gRESOimoAL43ouLVhLsHJpfyZS3ByKX/mYohkDpyIiDLHKRQiIkdxACciclSoA7iI9BWRrSKyQ0Qmh3ls7/hzReSAiGwwHmshImUist373jyEPNqLSLmIbBaRjSIyPqpcgsC6WrnEprasq5VLTtY1tAFcRAoAzAbQD0BXAMNFpGtYx/fMA9DX99hkAKuVUh0BrPba2VYNYJJSqguAXgDu9P4uosglI6zrWWJRW9b1LLlZV6VUKF8AegN42WhPATAlrOMbxy0CsMFobwVQ6MWFALZGkNMKAMW5kAvrytqyru7UNcwplAsA7DHae73HotZGKVUJAN731mEeXESKAFwGYE3UuaSJdU3A8dqyrgnkUl3DHMCllsfyeg2jiDQFsBTABKXUkajzSRPrWosY1JZ1rUWu1TXMAXwvgPZGux2A/4R4/ET2i0ghAHjfD4RxUBFphJofhIVKqWVR5pIh1tUnJrVlXX1ysa5hDuBvA+goIl8TkcYAhgFYGeLxE1kJoMSLS1Azt5VVIiIA5gDYrJSaGWUuAWBdDTGqLetqyNm6hjzxfz2AbQDeBzA1gg8eFgGoBFCFmjOMkQBaoubT4+3e9xYh5HElan4dXQ/gXe/r+ihyYV1ZW9bV3bryUnoiIkfxSkwiIkdxACcichQHcCIiR3EAJyJyFAdwIiJHcQAnInIUB3AiIkf9P60zxDIvCt1tAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "########################LAUNCH TENSORBOARD########################\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir='runs/MNIST')\n",
    "########################LAUNCH TENSORBOARD########################\n",
    "\n",
    "#device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # if we have GPU we will use it, if not, we use cpu.\n",
    "\n",
    "# hyper parameters\n",
    "input_size = 784 # our inputs from MNIST have a resolution of 28x28=784 if we flatten it.\n",
    "hidden_size = 100 \n",
    "num_classes = 10 # digits from 0-9\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 1e-3 # 1e-2\n",
    "\n",
    "# MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root = './intro_pytorch_data', train = True, transform = transforms.ToTensor(), download = True)\n",
    "test_dataset = torchvision.datasets.MNIST(root = './intro_pytorch_data', train = False, transform = transforms.ToTensor(), download = False)\n",
    "\n",
    "# DataLoader, Transformation\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# # testing the first batch of our dataloader 'torch.Size([100, 1, 28, 28])' 100 its the size of the batch, channels, width, height\n",
    "for i, (samples, labels) in enumerate(train_dataloader):\n",
    "    if i == 0:\n",
    "     print(samples.shape, labels.shape)   \n",
    "     break\n",
    "##Plotting the data of training##\n",
    "# for i in range(6):\n",
    "    # plt.subplot(2, 3, i+1)\n",
    "    # plt.imshow(samples[i][0],cmap = 'gray')\n",
    "# plt.show()\n",
    "\n",
    "##############################TENSORBOARD##############################\n",
    "img_grid = torchvision.utils.make_grid(samples) # first we want to create a grid with the train data\n",
    "writer.add_image('mnist_images', img_grid)\n",
    "# writer.close()\n",
    "# sys.exit() # to exit from the program\n",
    "##############################TENSORBOARD##############################\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # now we create our layers\n",
    "        self.l1 = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
    "        # self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(in_features=hidden_size, out_features=num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out\n",
    "        # note: we do not use the softmax activation function at the exit of l2 because \n",
    "        # we use CrossEntropyLoss which already has the softmax applied at the exit.\n",
    "        \n",
    "        \n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# define the loss function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "##############################TENSORBOARD##############################\n",
    "writer.add_graph(model, samples.view(-1, 28*28))\n",
    "writer.close()\n",
    "# sys.exit() # to exit from the program\n",
    "##############################TENSORBOARD##############################\n",
    "\n",
    "# Training Loop (batch training) \n",
    "number_total_steps = len(train_dataloader)\n",
    "\n",
    "##############################TENSORBOARD##############################\n",
    "# creating a loss and accuracy graph in Tensorboard\n",
    "running_loss = 0.0\n",
    "running_corrects = 0.0\n",
    "##############################TENSORBOARD##############################\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(X_train, y_train) in enumerate(train_dataloader):\n",
    "        # we have to reshape the data from 100, 1, 28, 28 to 100, 784(100 = num of batches, 784 = number of inputs)\n",
    "        X_train = X_train.view(-1, 28*28).to(device) # we reshape and then send the data to GPU\n",
    "        y_train = y_train.to(device) # send the data to GPU\n",
    "        \n",
    "        # Forward Pass\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        \n",
    "        # Clean the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Backward Pass\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        ##############################TENSORBOARD##############################\n",
    "        # creating a loss and accuracy graph in Tensorboard\n",
    "        running_loss += loss.item()\n",
    "        _, predictions = torch.max(outputs, dim = 1)\n",
    "        running_corrects += (predictions == y_train).sum().item()\n",
    "        ##############################TENSORBOARD##############################\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'epoch: {epoch+1}/{num_epochs}, step: {i+1}/{number_total_steps}, loss: {loss.item():.4f}')\n",
    "            ##############################TENSORBOARD##############################\n",
    "            # adding accuracy and loss curve stepwise to the TENSORBOARD\n",
    "            writer.add_scalar('training loss', running_loss / 100, epoch * number_total_steps + i)\n",
    "            writer.add_scalar('accuracy', running_corrects / 100, epoch * number_total_steps + i)\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "            ##############################TENSORBOARD##############################\n",
    "# Testing\n",
    "##############################TENSORBOARD##############################\n",
    "# creating a precision recall curve in Tensorboard\n",
    "labels = []\n",
    "preds = []\n",
    "##############################TENSORBOARD##############################\n",
    "with torch.no_grad():\n",
    "    n_correct_predictions = 0\n",
    "    n_samples = 0\n",
    "    for X_test, y_test in test_dataloader:\n",
    "        # we have to reshape the data from 100, 1, 28, 28 to 100, 784(100 = num of batches, 784 = number of inputs)\n",
    "        X_test = X_test.view(-1, 28*28).to(device) # we reshape and then send the data to GPU\n",
    "        y_test = y_test.to(device) # send the data to GPU    \n",
    "        outputs = model(X_test)\n",
    "        \n",
    "        #return value, index = _, predictions\n",
    "        _, predictions = torch.max(outputs, dim = 1)\n",
    "        n_samples +=y_test.shape[0]\n",
    "        n_correct_predictions += (predictions == y_test).sum()\n",
    "        ##############################TENSORBOARD##############################\n",
    "        # we need probabilities, so we will applied a softmax function to the output of the nn\n",
    "        class_predictions = [F.softmax(output, dim = 0) for output in outputs] # we calculate the softmax for each output in ouputs\n",
    "        \n",
    "        preds.append(class_predictions)\n",
    "        labels.append(predictions)\n",
    "    \n",
    "    preds = torch.cat([torch.stack(batch) for batch in preds])\n",
    "    labels = torch.cat(labels) #concatenate all the elements in our list in one dimensional tensor\n",
    "        ##############################TENSORBOARD##############################\n",
    "    \n",
    "    accuracy = 100.0 * n_correct_predictions / n_samples\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    \n",
    "    ##############################TENSORBOARD##############################\n",
    "    #we add the precision recall curve to Tensorboar\n",
    "    classes = range(10) # digits from 0-9\n",
    "    for i in classes:\n",
    "        labels_i = labels == i\n",
    "        preds_i = preds[:, i]\n",
    "        writer.add_pr_curve(str(i),labels_i,preds_i, global_step = 0)\n",
    "        writer.close()\n",
    "    ##############################TENSORBOARD##############################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HYPERPARAMETER SEARCH (BEST LEARNING RATE & BATCH SIZE MATCH TOGETHER) WITH **TENSORBOARD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/1, step: 15000/30000, loss: 1.9466\n",
      "epoch: 1/1, step: 30000/30000, loss: 2.5383\n",
      "Accuracy: 9.82, batch_size: 2\n",
      "epoch: 1/1, step: 15000/30000, loss: 0.3414\n",
      "epoch: 1/1, step: 30000/30000, loss: 0.0000\n",
      "Accuracy: 90.37, batch_size: 2\n",
      "epoch: 1/1, step: 15000/30000, loss: 0.0205\n",
      "epoch: 1/1, step: 30000/30000, loss: 0.1926\n",
      "Accuracy: 93.44, batch_size: 2\n",
      "Accuracy: 71.08, batch_size: 64\n",
      "Accuracy: 95.32, batch_size: 64\n",
      "Accuracy: 89.35, batch_size: 64\n",
      "Accuracy: 83.49, batch_size: 1024\n",
      "Accuracy: 93.76, batch_size: 1024\n",
      "Accuracy: 70.62, batch_size: 1024\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir='runs/MNIST')\n",
    "\n",
    "#device config\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # if we have GPU we will use it, if not, we use cpu.\n",
    "device = torch.device('mps') #mac\n",
    "\n",
    "# hyper parameters\n",
    "input_size = 784 # our inputs from MNIST have a resolution of 28x28=784 if we flatten it.\n",
    "hidden_size = 100 \n",
    "num_classes = 10 # digits from 0-9\n",
    "num_epochs = 1\n",
    "\n",
    "# MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root = './intro_pytorch_data', train = True, transform = transforms.ToTensor(), download = True)\n",
    "test_dataset = torchvision.datasets.MNIST(root = './intro_pytorch_data', train = False, transform = transforms.ToTensor(), download = False)\n",
    "\n",
    "\n",
    "# # testing the first batch of our dataloader 'torch.Size([100, 1, 28, 28])' 100 its the size of the batch, channels, width, height\n",
    "# for i, (samples, labels) in enumerate(train_dataloader):\n",
    "#     if i == 0:\n",
    "#      print(samples.shape, labels.shape)   \n",
    "#      break\n",
    "# ##Plotting the data of training##\n",
    "# for i in range(6):\n",
    "#     plt.subplot(2, 3, i+1)\n",
    "#     plt.imshow(samples[i][0],cmap = 'gray')\n",
    "# plt.show()\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # now we create our layers\n",
    "        self.l1 = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
    "        # self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(in_features=hidden_size, out_features=num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out\n",
    "        # note: we do not use the softmax activation function at the exit of l2 because \n",
    "        # we use CrossEntropyLoss which already has the softmax applied at the exit.\n",
    "        \n",
    "        \n",
    "batch_sizes = [2, 64, 1024]\n",
    "learning_rates = [1e-1, 1e-2, 1e-4]\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    \n",
    "    for learning_rate in learning_rates:\n",
    "        step_test = 0 #global step for tensorboard(test)    \n",
    "        step = 0 #global step for tensorboard(train)    \n",
    "        model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "        \n",
    "        writer = SummaryWriter(f'runs/MNIST/MiniBatchSize: {batch_size} LR: {learning_rate}')\n",
    "        \n",
    "        # DataLoader, Transformation\n",
    "        train_dataloader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "        test_dataloader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "        \n",
    "        # define the loss function and Optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "        # Training Loop (batch training) \n",
    "        number_total_steps = len(train_dataloader)\n",
    "        \n",
    "        ##############################TENSORBOARD##############################\n",
    "        # creating a loss and accuracy graph in Tensorboard\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "        ##############################TENSORBOARD##############################\n",
    "        for epoch in range(num_epochs):\n",
    "            for i,(X_train, y_train) in enumerate(train_dataloader):\n",
    "                # we have to reshape the data from 100, 1, 28, 28 to 100, 784(100 = num of batches, 784 = number of inputs)\n",
    "                X_train = X_train.view(-1, 28*28).to(device) # we reshape and then send the data to GPU\n",
    "                y_train = y_train.to(device) # send the data to GPU\n",
    "                \n",
    "                # Forward Pass\n",
    "                outputs = model(X_train)\n",
    "                loss = criterion(outputs, y_train)\n",
    "                \n",
    "                # Clean the gradients\n",
    "                optimizer.zero_grad()\n",
    "                # Backward Pass\n",
    "                loss.backward()\n",
    "                # Update the weights\n",
    "                optimizer.step()\n",
    "\n",
    "                ##############################TENSORBOARD##############################\n",
    "                # creating a loss and accuracy graph in Tensorboard\n",
    "                running_loss += loss.item()\n",
    "                _, predictions = torch.max(outputs, dim = 1)\n",
    "                running_corrects += (predictions == y_train).sum().item()\n",
    "                \n",
    "                # adding accuracy and loss curve stepwise to the TENSORBOARD\n",
    "                writer.add_scalar('training loss', loss, global_step = step)\n",
    "                writer.add_scalar('trining accuracy', running_corrects / y_train.size(0), global_step = step) \n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0.0\n",
    "                step+=1 #global step for tensorboard\n",
    "                ##############################TENSORBOARD##############################\n",
    "                if (i + 1) % 15000 == 0:\n",
    "                    print(f'epoch: {epoch+1}/{num_epochs}, step: {i+1}/{number_total_steps}, loss: {loss.item():.4f}')\n",
    "                    \n",
    "        # Testing\n",
    "        with torch.no_grad():\n",
    "            step_test += 1 #global step for tensorboard(test) \n",
    "            n_correct_predictions = 0\n",
    "            n_samples = 0\n",
    "            for X_test, y_test in test_dataloader:\n",
    "                # we have to reshape the data from 100, 1, 28, 28 to 100, 784(100 = num of batches, 784 = number of inputs)\n",
    "                X_test = X_test.view(-1, 28*28).to(device) # we reshape and then send the data to GPU\n",
    "                y_test = y_test.to(device) # send the data to GPU    \n",
    "                model.eval()\n",
    "                outputs = model(X_test)\n",
    "                \n",
    "                #return 'value', 'index' = '_', 'predictions'\n",
    "                _, predictions = torch.max(outputs, dim = 1)\n",
    "                n_samples +=y_test.shape[0]\n",
    "                n_correct_predictions += (predictions == y_test).sum()\n",
    "            \n",
    "            accuracy_test = 100.0 * n_correct_predictions / n_samples\n",
    "            writer.add_scalar('test accuracy', accuracy_test/100, global_step = step_test)\n",
    "            print(f'Accuracy: {accuracy_test:.2f}, batch_size: {batch_size}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation for the results in TENSORBOARD:** <BR>\n",
    "* *Smaller batch_sizes seems to correlate with lower learning rates, which can make sense because we are doing a lot of more updates, and when we compute gradients for largers batch_sizes, the gradient is more exact, so we can afford having a larger learning rate.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"20\"></a> \n",
    "### SAVING AND LOADING MODELS<br>\n",
    "\n",
    "[Ir a índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "######## SAVING THE COMPLETE MODEL ########\n",
    "torch.save(model, 'model_file_name.pth')\n",
    "\n",
    "# LOADING THE MODEL\n",
    "model_in_gpu = torch.load('model_file_name.pth', map_location= 'cuda:0') # if we want to load the model direct into GPU\n",
    "model_in_gpu.eval() # set the model in evaluation mode\n",
    "\n",
    "################################################################################################\n",
    "################################################################################################\n",
    "\n",
    "######## ANOTHER WAY TO SAVE THE MODEL LIKE STATE DICT ########\n",
    "torch.save.(model.state_dict(), 'model_file_name.pth')\n",
    "\n",
    "# model must be created again with parameters\n",
    "model = Model(*args, **kwargs) \n",
    "model.load_state_dict(torch.load(\"model_file_name.pth\"))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "466813897a52447f1831c184b0700fb7b7f042a70becf90568dd3beaa877b3ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
