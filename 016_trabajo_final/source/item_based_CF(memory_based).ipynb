{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "0.8952100532981588\n",
      "{'name': 'pearson', 'min_k': 5, 'k': 40, 'user_based': False}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from surprise import Reader, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.prediction_algorithms.knns import KNNWithMeans\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from utils.leave_one_last import leave_one_last_item\n",
    "\n",
    "\n",
    "\n",
    "my_seed = 1203\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "\n",
    "path = '../data/movie_lens_small/ratings.csv'\n",
    "\n",
    "movies = pd.read_csv(path)\n",
    "\n",
    "df = movies.copy()\n",
    "df.drop(columns=['timestamp'], inplace=True)\n",
    "#las columnas deben tener estos nombres, y estar en este orden para que load_from_df las lea\n",
    "df.columns = [\"userID\", \"itemID\", \"rating\"]\n",
    "\n",
    "trainset, testset = leave_one_last_item(df, 'userID')\n",
    "\n",
    "#creo un objeto de clase Reader para parsear la data del archivo\n",
    "reader = Reader(line_format='user item rating',\n",
    "                rating_scale=(np.min(df['rating']), np.max(df['rating'])))\n",
    "\n",
    "train = Dataset.load_from_df(trainset[[\"userID\", \"itemID\", \"rating\"]], reader)\n",
    "test = Dataset.load_from_df(testset[[\"userID\", \"itemID\", \"rating\"]], reader)\n",
    "\n",
    "\n",
    "#instancio el modelo\n",
    "# CF_itembased = KNNWithMeans(k=40, min_k=1, \n",
    "#                             sim_options={'name':'pearson',\n",
    "#                                           'user_based':False,\n",
    "#                                        },\n",
    "#                             verbose=True)\n",
    "\n",
    "# cv = cross_validate(CF_itembased, \n",
    "#                      train,\n",
    "#                      measures = ['RMSE', 'MAE'],\n",
    "#                      cv = 5,\n",
    "#                      n_jobs = -1,\n",
    "#                      )\n",
    "\n",
    "param_grid = {\n",
    "               \"name\": [\"pearson\"],\n",
    "               \"min_k\": [1, 5, 12],\n",
    "               \"k\": [20, 40, 50],\n",
    "               \"user_based\": [False],\n",
    "            }\n",
    "\n",
    "gs = GridSearchCV(KNNWithMeans, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "\n",
    "gs.fit(train)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score[\"rmse\"])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params[\"rmse\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explicar porque usaria rmse o MAE para elegir el mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x133976eb0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CF_itembased = gs.best_estimator[\"rmse\"]\n",
    "\n",
    "CF_itembased.fit(train.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como mido las metricas de test?\n",
    "#puedo fitear a partir de otra metrica distinta a mae o rmse?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''In the Surprise library, the \"was_impossible\" flag indicates that the model was unable to make a prediction for the given user-item pair. This can happen for two reasons:\n",
    "\n",
    "    User or item is unknown: The user or item may not have been included in the training data. This can happen if the user or item is new to the system, or if it has been removed from the dataset.\n",
    "\n",
    "    Insufficient data: The model may not have enough data to make a reliable prediction for the given user-item pair. This can happen if the user or item has not been rated by many other users, or if the ratings that are available are not very informative.\n",
    "\n",
    "In either case, the \"was_impossible\" flag is a warning that the model's prediction should be treated with caution. If you are relying on the model to make accurate predictions, you may want to consider filtering out user-item pairs that are marked as \"was_impossible\".'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tengo que separar bien los datos de movielens, como dice el libro, por usuario, para que queden usuarios en test y train, de paso podria ver si puedo usar el dataset grande.\n",
    "\n",
    "- Tambien, me falta entender que es \"was imposible\" que me devuelve el modelo\n",
    "\n",
    "- Tengo que ver si puedo usar las metricas que vi, como Mean Average Precision o la que toma en cuenta el ranking\n",
    "\n",
    "- Me falta ver como predecir un TOP N ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Me tengo que crear yo una funcion o una clase que tenga un metodo, que reciba un dataframe, que tenga [USUARIO, ITEM, RATING], y que devuelva dos dataframe TRAIN y TEST, que intente separar por usuario en ambos dataframe.\n",
    "\n",
    "- Voy a ver como manejo el asunto de que no tenga suficientes usuarios para que haya en train y test, que hago ahi??\n",
    "\n",
    "- Cuantos usuarios para train y cuantos para test? por porcentaje?\n",
    "\n",
    "- El paper hablaba de Leave One Last item, donde cada registro corresponde a (usuario, item) par por usuario. La ventaja es que maximiza el numero de transacciones en el dataset que pueden ser usadas para entrenar el recomendador. Para test en este metodo, solo la ultima transaccion del usuario es utilizada como test y la anteultima como validation. Los demas registros, se utilizan para train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
