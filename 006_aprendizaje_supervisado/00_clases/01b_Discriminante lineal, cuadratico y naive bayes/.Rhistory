---
title: "LdaQdaNB"
knitr::opts_chunk$set(echo = TRUE)
```{r}
```{r}
library(klaR)
library(MASS)
library(klaR)
library(tidyverse)
library(MASS)
library(klaR)
```{r muestra de entrenamiento}
iris
training_sample <- sample(c(TRUE, FALSE), nrow(iris), replace = T, prob = c(0.75,0.25))
train <- iris[training_sample, ]
test <- iris[!training_sample, ]
set.seed(789)
training_sample <- sample(c(TRUE, FALSE), nrow(iris), replace = T, prob = c(0.75,0.25))
train <- iris[training_sample, ]
test <- iris[!training_sample, ]
```{r lda}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(MASS)
library(klaR)
set.seed(789)
training_sample <- sample(c(TRUE, FALSE), nrow(iris), replace = T, prob = c(0.75,0.25))
train <- iris[training_sample, ]
test <- iris[!training_sample, ]
lda.iris = lda(Species ~ ., train)
lda.iris$means # vector de medias para cada grupo.
lda.iris$scaling # pesos de las hiperplanos separadores.
plot(lda.iris,col=as.integer(train$Species))
plot(lda.iris, dimen = 1, type = "b")
partimat(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data=train, method="lda")
lda.test <- predict(lda.iris,test)
test$lda <- lda.test$class
table(test$lda,test$Species)
library(rstatix)
box_m(iris[, -5], iris[, 5])
qda.iris = qda(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, train)
qda.iris #mostramos la salida
partimat(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data=train, method="qda")
qda.test <- predict(qda.iris,test)
test$qda <- qda.test$class
table(test$qda,test$Species)
library(e1071)
library(naivebayes)
nb.iris <- naiveBayes(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, train)
nbiris.test <- predict(nb.iris,test)
table(nbiris.test,test$Species)
qda.test = predict(qda.iris,test)
qdairis.test=qda.test$class
tab <- table(test$Species, qdairis.test, dnn =c("Real","Predicha"))
tab
library(caret)
cm.nb.iris=confusionMatrix(tab)
cm.nb.iris
library(mlbench)
data("BreastCancer")
bc=na.omit(BreastCancer[,-1]) #saco los datos faltantes.
set.seed(123)
training_sample <- sample(c(TRUE, FALSE), nrow(bc), replace = T, prob = c(0.75,0.25))
train <- bc[training_sample, ]
test <- bc[!training_sample, ]
lda.bc <- lda(Class ~ ., train)
lda.bc
lda.test.bc <- predict(lda.bc,test)
confusion <- table(test$Class, lda.test.bc$class, dnn = c("Real", "Predicha"))
cm.lda.bc=confusionMatrix(confusion)
cm.lda.bc
library(ROCR) #tiene sentido para clasificadores binarios.
#cjto de datos con predicciones y etiquetas verdaderas
df <- data.frame(predictions= as.numeric(lda.test.bc$class),labels=as.numeric(test$Class))
#como factores no funciona
pred <- prediction(as.numeric(df$predictions), df$labels)
perf <- performance(pred,"tpr","fpr")
auc.pred <- performance(pred, measure = "auc")
auc.pred@y.values
plot(perf,colorize=TRUE)
qda.iris$scaling
lda.iris$scaling
qda.iris = qda(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, train)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(MASS)
library(klaR)
set.seed(789)
training_sample <- sample(c(TRUE, FALSE), nrow(iris), replace = T, prob = c(0.75,0.25))
train <- iris[training_sample, ]
test <- iris[!training_sample, ]
lda.iris = lda(Species ~ ., train)
lda.iris$means # vector de medias para cada grupo.
lda.iris$scaling # pesos de las hiperplanos separadores.
plot(lda.iris,col=as.integer(train$Species))
plot(lda.iris, dimen = 1, type = "b")
partimat(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data=train, method="lda")
lda.test <- predict(lda.iris,test)
test$lda <- lda.test$class
table(test$lda,test$Species)
library(rstatix)
box_m(iris[, -5], iris[, 5])
qda.iris = qda(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, train)
qda.iris #mostramos la salida
partimat(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data=train, method="qda")
# qda.iris$scaling
lda.iris$scaling
