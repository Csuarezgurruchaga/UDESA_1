Spotify_r <- read.table("~/Desktop/UDESA/007_aprendizaje_no_supervisado/01_Trabajos_practicos/zz_TP_integrador/Spotify_r/Spotify_r.Rproj", quote="\"")
View(Spotify_r)
dataset_spotify <- read.csv("~/Desktop/UDESA/007_aprendizaje_no_supervisado/01_Trabajos_practicos/zz_TP_integrador/Spotify_r/dataset_spotify.csv")
View(dataset_spotify)
knitr::opts_chunk$set(echo = TRUE)
dataset_spotify <- read.csv("~/Desktop/UDESA/007_aprendizaje_no_supervisado/01_Trabajos_practicos/zz_TP_integrador/Spotify_r/dataset_spotify.csv")
df <- read.csv("~/Desktop/UDESA/007_aprendizaje_no_supervisado/01_Trabajos_practicos/zz_TP_integrador/Spotify_r/dataset_spotify.csv")
df
scale(df)
scale(df)
scale(df$energy)
df <- read.csv("~/Desktop/UDESA/007_aprendizaje_no_supervisado/01_Trabajos_practicos/zz_TP_integrador/Spotify_r/dataset_spotify.csv")
summary(df)
select_if(df, is.numeric)
library("dplyr")
select_if(df, is.numeric)
summary(select_if(df, is.numeric))
df_numeric = scale(select_if(df, is.numeric))
df_numeric = scale(select_if(df, is.numeric))
df_numeric
df_numeric = scale(select_if(df, is.numeric))
head(df_numeric)
df_numeric = scale(select_if(df, is.numeric))
summary(df_numeric)
nrow(df)
library("dplyr")
library(fpc)
library(dbscan)
dbs= dbscan(df_numeric, eps = 0.15, MinPts = 2)
dbs #lista con objetos entre ellos los clusters
#### EJERCICIO DBSCAN
## Librerias para dbscan
library(fpc)
library(dbscan)
### EJEMPLO DE PRUEBA
library(factoextra)
data("multishapes")
# write.csv(multishapes, "multishapes.csv")
plot(multishapes[,1:2])
## Libreria fpc (opcional probar la otra libreria)
scan_fpc = dbscan(multishapes[,1:2], eps = 0.15, MinPts = 2)
scan_fpc #lista con objetos entre ellos los clusters
# Seleccionar el esp: knndist
kNNdist(multishapes, k = 2) # calcula las distancias al 4to vecino mas cercano sin ordenar
kNNdistplot(multishapes, k =  2) # hace el plot con las distancias ordenadas de menos a mayor
abline(h=0.15, lty=2)
plot(multishapes[,1:2], col=scan_fpc$cluster)
### EJERCICIO PARA HACER EN CLASE
# Utilizar el dataset "banknote.txt"
# Algunas notas de cambio son falsas con lo cual pueden diferir un poco de las verdaderas.
# Lucas mezclo los subindices y perdio las etiquetas antes de empezar la clase.
# Utilizar bdscan para encontrarlas.
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
eps_plot
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=2)
eps_plot
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
eps_plot
dbs= dbscan(df_numeric, eps = 0.15, MinPts = 3)
dbs #lista con objetos entre ellos los clusters
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
eps_plot;
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
eps_plot %>% abline(h = 0.45, lty = 2)
eps_plot
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
eps_plot %>% abline(h = 0.45, lty = 2)
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
# eps_plot %>% abline(h = 0.45, lty = 2)
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
eps_plot %>% abline(h = 4, lty = 2)
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
eps_plot %>% abline(h = 3, lty = 2)
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
eps_plot %>% abline(h = 3.8, lty = 2)
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
eps_plot %>% abline(h = 3.8, lty = 2, c = "red")
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
eps_plot %>% abline(h = 3.8, lty = 2, c = c("red"))
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
eps_plot %>% abline(h = 3.8, lty = 2, col = c("red"))
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
eps_plot %>% abline(h = 3.8, lty = 2, col = c("blue"))
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
eps_plot %>% abline(h = 3.8, lty = 2, col = c("darkblue"))
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=2)
# to draw an optimum line
eps_plot %>% abline(h = 3.8, lty = 2, col = c("darkblue"))
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=4)
# to draw an optimum line
eps_plot %>% abline(h = 3.8, lty = 2, col = c("darkblue"))
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
eps_plot %>% abline(h = 3.8, lty = 2, col = c("darkblue"))
dbs= dbscan(df_numeric, eps = 3.8, MinPts = 3)
dbs #lista con objetos entre ellos los clusters
library("dplyr")
library(fpc)
library(dbscan)
library(FactoMineR)
library(factoextra)
library(fpc)
library(mclust)
library(NbClust)
library(cluster)
knitr::opts_chunk$set(echo = TRUE)
library(FactoMineR)
library(factoextra)
library(fpc)
library(mclust)
library(NbClust)
library(cluster)
## Dataset Iris
data(iris)
df = iris[,-5]
fviz_dist(dist(df), show_labels = FALSE) + labs(title = "Iris data")
K = 3
df_kmeans = kmeans(df, K)
# Conociendo las etiquetas podemos usar un indice de validacion externa para analizar el algoritmo
adjustedRandIndex(df_kmeans$cluster, iris$Species)
table(kmeans=df_kmeans$cluster, Species = iris$Species)
df_kmeans_stability = clusterboot(df, clustermethod=kmeansCBI, k=K)
df_kmeans_stability
df_kmeans_silhouette = silhouette(df_kmeans$cluster, dist(df))
plot(df_kmeans_silhouette)
# Elbow method
fviz_nbclust(df, kmeans, method = "wss") +
labs(subtitle = "Elbow")
# Elbow method
fviz_nbclust(df, kmeans, method = "silhouette") + labs(subtitle = "Elbow")
dbs$cluster
dist(df)
nrow(dist(df))
dist(df)
df_kmeans_silhouette = silhouette(dbs$cluster, dist(df))
df_kmeans_silhouette = silhouette(dbs$cluster, dist(df))
df
dist(df)
df
df_kmeans_silhouette = silhouette(dbs$cluster, dist(df_numeric))
plot(df_kmeans_silhouette)
dist(df_numeric)
df_kmeans_silhouette = silhouette(dbs$cluster, dist(df_numeric))
# plot(df_kmeans_silhouette)
df_kmeans_silhouette
df_kmeans_silhouette = silhouette(dbs$cluster, dist(df_numeric))
plot(df_kmeans_silhouette)
# Elbow method
fviz_nbclust(df_numeric, dbs, method = "wss") +
labs(subtitle = "Elbow")
# Elbow method
fviz_nbclust(df_numeric, dbscan, method = "wss") +
labs(subtitle = "Elbow")
# Elbow method
fviz_nbclust(df_numeric, dbscan, method = "silhouette") +
labs(subtitle = "Elbow")
# Elbow method
fviz_nbclust(df_numeric, dbscan, method = "silhouette") +
labs(subtitle = "Elbow")
# Elbow method
fviz_nbclust(df_numeric, dbscan, method = "wss") +
labs(subtitle = "Elbow")
fviz_nbclust(df_numeric, dbscan, method = "silhouette")
summary(df_kmeans_silhouette)
s_score_dbs = silhouette(dbs$cluster, dist(df_numeric))
s_score_dbs = silhouette(dbs$cluster, dist(df_numeric))
summary(s_score_dbs)
s_score_dbs = silhouette(dbs$cluster, dist(df_numeric))
summary(s_score_dbs)
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
eps_plot %>% abline(h = 3.8, lty = 2, col = c("darkblue"))
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
eps_plot %>% abline(h = 3.8, lty = 2, col = c("darkblue"))
eps_plot %>% abline(h = 4.8, lty = 2, col = c("darkblue"))
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
eps_plot %>% abline(h = 3.8, lty = 2, col = c("darkblue"))
eps_plot %>% abline(h = 4.5, lty = 2, col = c("darkblue"))
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
eps_plot %>% abline(h = 3.8, lty = 2, col = c("darkblue"))
eps_plot %>% abline(h = 4.6, lty = 2, col = c("darkblue"))
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
eps_plot %>% abline(h = 3.8, lty = 2, col = c("darkblue"))
eps_plot %>% abline(h = 4.5, lty = 2, col = c("darkblue"))
dbs_1= dbscan(df_numeric, eps = 3.8, MinPts = 3)
dbs_2= dbscan(df_numeric, eps = 4.5, MinPts = 3)
dbs_1 #lista con objetos entre ellos los clusters
dbs_2
s_score_dbs_1 = silhouette(dbs_1$cluster, dist(df_numeric))
s_score_dbs_2 = silhouette(dbs_2$cluster, dist(df_numeric))
summary(s_score_dbs_1)
summary(s_score_dbs_2)
s_score_dbs_1 = silhouette(dbs_1$cluster, dist(df_numeric))
s_score_dbs_2 = silhouette(dbs_2$cluster, dist(df_numeric))
summary(s_score_dbs_1)
summary(s_score_dbs_2)
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
eps_plot %>% abline(h = 3.8, lty = 2, col = c("darkblue"))
eps_plot %>% abline(h = 4.5, lty = 2, col = c("darkred"))
fviz_nbclust(df, kmeans, nstart = 25, method = "gap_stat", nboot = 50) + labs(subtitle = "Gap")
fviz_nbclust(df_numeric, dbscan, method = "silhouette") + labs(subtitle = "Elbow")
fviz_nbclust(df_numeric, dbs_1, method = "silhouette") + labs(subtitle = "Elbow")
fviz_nbclust(df_numeric, kmeans, method = "silhouette") + labs(subtitle = "Elbow")
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
eps_plot %>% abline(h = 3.8, lty = 2, col = c("darkblue")) #opcion 1 de eps
eps_plot %>% abline(h = 4.5, lty = 2, col = c("darkred"))  #opcion 2 de eps
eps_plot(main = c("asd"))
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
eps_plot %>% abline(h = 3.8, lty = 2, col = c("darkblue")) #opcion 1 de eps
eps_plot %>% abline(h = 4.5, lty = 2, col = c("darkred"))  #opcion 2 de eps
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3, main = c("as"))
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
eps_plot %>% abline(h = 3.8, lty = 2, col = c("darkblue")) #opcion 1 de eps
eps_plot %>% abline(h = 4.5, lty = 2, col = c("darkred"))  #opcion 2 de eps
gmm=Mclust(df_numeric, G = 2)
gmm
# Elbow method
fviz_nbclust(df_numeric, Mclust, method = "wss") +
labs(subtitle = "Elbow")
gmm=Mclust(df_numeric)
gmm
gmm=Mclust(df_numeric)
gmm$G
gmm=Mclust(df_numeric)
library(mclust)
library(MASS)
# write.csv(geyser, file = "geyser_r.csv")
gmm=Mclust(geyser, G = 2) #solo estima la cantidad de correcta de clusters
summary(gmm, parameters=T)
best_gmm = Mclust(geyser) #Solo estima la mejor cantidad de cluster a partir del BIC
BIC = mclustBIC(geyser)
BIC
# summary(bic)
densidad=densityMclust(geyser, G=2)
summary(mclustBIC(geyser, G=2))
# Ploteamos la funcion de densidad de las gauseanas multivariadas estimadas con
# las que clusterizo los datos
densidad_best_gmm=densityMclust(geyser)
plot(densidad_best_gmm, what="density", data=geyser, col = "blue")
summary(mclustBIC(geyser))
geyser_2 = geyser
geyser_2["cluster"]=best_gmm$classification
geyser_2["probabilidad_clasificacion"]=round(best_gmm$uncertainty, 3)
geyser_2
# Outlier
# Aqui observamos que la observacion que se aprecia mas alejada, tiene un valor de
# probabilidad de pertenecer al cluster 4, bajo. Lo cual es logico.
geyser[geyser["waiting"]==108,]
plot(dexp(x = 1:100,rate = 1/20), col = "blue")
x1 = rexp(rate = 1/20, n = 50)
x2 = rexp(rate = 1/10, n = 50)
x3 = rexp(rate = 1/20, n = 50)
x4 = rexp(rate = 1/10, n = 50)
data = data.frame(rbind(cbind(x1,x2),cbind(x3,x4)))
gmm_no_gaussean=Mclust(data)
densidad_gmm_no_gaussean=densityMclust(data)
plot(densidad_gmm_no_gaussean, what="density", data=data, col = "blue")
geyser_outliers=geyser
geyser_outliers[5,"waiting"]=150
geyser_outliers[7,"waiting"]=150
# geyser_outliers[5,"duration"]=50
# geyser_outliers[8,"duration"]=40
densidad_outliers_gmm=densityMclust(geyser_outliers)
outliers_gmm = Mclust(geyser_outliers)
plot(densidad_outliers_gmm, what="density", data=geyser_outliers, col = "blue")
outliers_gmm$G # Ver coloreando clusters, a ver que hace con los outliers
geyser_outliers["clusters"] = outliers_gmm$classification
plot(x =geyser_outliers$waiting , y = geyser_outliers$duration, col = geyser_outliers$clusters)
geyser_outliers=geyser
geyser_outliers[5,"waiting"]=150
geyser_outliers[7,"waiting"]=150
geyser_outliers[5,"duration"]=50
geyser_outliers[8,"duration"]=40
densidad_outliers_gmm=densityMclust(geyser_outliers)
plot(densidad_outliers_gmm, what="density", data=geyser_outliers, col = "blue")
outliers_gmm$G # Ver coloreando clusters, a ver que hace con los outliers
geyser_outliers["clusters"] = outliers_gmm$classification
plot(x =geyser_outliers$waiting , y = geyser_outliers$duration, col = geyser_outliers$clusters)
geyser_outliers=geyser
geyser_outliers[5,"waiting"]=150
geyser_outliers[5,"duration"]=50
geyser_outliers[7,"waiting"]=150
geyser_outliers[7,"duration"]=51.3
geyser_outliers[9,"waiting"]=149.5
geyser_outliers[9,"duration"]=49.2
geyser_outliers[11,"waiting"]=148
geyser_outliers[11,"duration"]=52
geyser_outliers[13,"waiting"]=147.3
geyser_outliers[13,"duration"]=51.87
geyser_outliers[22,"waiting"]=147.1
geyser_outliers[22,"duration"]=52.7
geyser_outliers[23,"waiting"]=148.5
geyser_outliers[23,"duration"]=52.2
# write.csv(geyser_outliers, file = "geyser_outliers_r.csv")
densidad_outliers_gmm=densityMclust(geyser_outliers)
plot(densidad_outliers_gmm, what="density", data=geyser_outliers, col = "blue")
Mclust(geyser_outliers)$G
geyser_outliers["clusters"] = outliers_gmm$classification
plot(x =geyser_outliers$waiting , y = geyser_outliers$duration, col = geyser_outliers$clusters)
# Observamos la certeza o seguridad con la que clasifico a los outliers en sus clusters
outliers_gmm$uncertainty[c(5, 7, 9, 11, 13, 22, 23)]
outliers_gmm$uncertainty[2]
1-round(outliers_gmm$z[2,],5)
rows = sample(x = 1:300,20)
geyser_alta_dimension=geyser[rows,c("waiting","duration")]
mu1 = mean(geyser_alta_dimension$waiting)
tita1 = sd(geyser_alta_dimension$waiting)
mu2 = mean(geyser_alta_dimension$duration)
tita2 = sd(geyser_alta_dimension$duration)
new_waiting = replicate(200,rnorm(n = 20, mean = mu1, sd = tita1) + runif(1, min=50, max=100))
new_duration = replicate(200,rnorm(n = 20, mean = mu2, sd = tita2) + runif(1, min=1, max=4))
data_alta_dimension = data.frame(cbind(geyser_alta_dimension,new_waiting,new_duration))
data_alta_dimension
# densidad_alta_dimension_gmm=densityMclust(data_alta_dimension)
# plot(densidad_alta_dimension_gmm, what="density", data=data_alta_dimension, col = "blue")
gmm_alta_dimensionalidad=Mclust(data_alta_dimension)
gmm_alta_dimensionalidad$G
knitr::opts_chunk$set(echo = TRUE)
library("dplyr")
library(fpc)
library(dbscan)
library(FactoMineR)
library(factoextra)
library(fpc)
library(mclust)
library(NbClust)
library(cluster)
df <- read.csv("~/Desktop/UDESA/007_aprendizaje_no_supervisado/01_Trabajos_practicos/zz_TP_integrador/Spotify_r/dataset_spotify.csv")
summary(df)
df_numeric = scale(select_if(df, is.numeric))
summary(df_numeric)
gmm=Mclust(df_numeric)
# to plot the eps values
eps_plot = kNNdistplot(df_numeric, k=3)
# to draw an optimum line
eps_plot %>% abline(h = 3.8, lty = 2, col = c("darkblue")) #opcion 1 de eps
eps_plot %>% abline(h = 4.5, lty = 2, col = c("darkred"))  #opcion 2 de eps
dbs_1= dbscan(df_numeric, eps = 3.8, MinPts = 3)
dbs_2= dbscan(df_numeric, eps = 4.5, MinPts = 3)
dbs_1 #lista con objetos entre ellos los clusters
dbs_2
s_score_dbs_1 = silhouette(dbs_1$cluster, dist(df_numeric))
s_score_dbs_2 = silhouette(dbs_2$cluster, dist(df_numeric))
summary(s_score_dbs_1)
summary(s_score_dbs_2)
silhouette(gmm$classification, dist(df_numeric))
s_score_gmm=silhouette(gmm$classification, dist(df_numeric))
summary(s_score_gmm)
ks.test(df_numeric,"dnorm")
gmm$classification
df_numeric$labels_gmm=gmm$classification
df_numeric$labels_gmm=gmm$classification
df_numeric
df_numeric = scale(select_if(df, is.numeric))
summary(df_numeric)
df_numeric_gmm[,"labels_gmm"]=gmm$classification
df_numeric_gmm = df_numeric
df_numeric_gmm = df_numeric
df_numeric_gmm
df_numeric_gmm = df_numeric
df_numeric_gmm[,"labels_gmm"] = gmm$classification
df_numeric_gmm = df_numeric
df_numeric_gmm[,"labels_gmm"] = gmm$classification
df_numeric_gmm = df_numeric
df_numeric_gmm[,c("labels_gmm")] = gmm$classification
df_numeric_gmm = df_numeric
df_numeric_gmm["labels_gmm"] = gmm$classification
df_numeric_gmm
# Elbow method
fviz_nbclust(df, kmeans, method = "wss") +
labs(subtitle = "Elbow")
# Elbow method
fviz_nbclust(df_numeric, kmeans, method = "wss") +
labs(subtitle = "Elbow")
fviz_nbclust(df_numeric, kmeans, method = "silhouette") + labs(subtitle = "Elbow")
km_silhoutte = silhouette(km$cluster, dist(df_numeric))
km=kmeans(df_numeric, 2)
km_silhoutte = silhouette(km$cluster, dist(df_numeric))
plot(km_silhoutte)
fviz_nbclust(df_numeric, kmeans, nstart = 25, method = "gap_stat", nboot = 50) + labs(subtitle = "Gap")
km$cluster
df_numeric["km_lables"] = km$cluster
df_numeric
df_numeric["km_lables"] = km$cluster
summary(df_numeric)
df_numeric = scale(select_if(df, is.numeric))
summary(df_numeric)
df_numeric[,"km_lables"] = km$cluster
km_labels = km$cluster
cbind(df_numeric, km_labels)
km_labels = km$cluster
cbind(df, km_labels)
km_labels = km$cluster
df = cbind(df, km_labels)
summary(df)
df
df["km_labels"]
df["km_labels"]==1
df[df["km_labels"]==1]
df[df["km_labels"]==0]
df[df["km_labels"]==1]
df[,df["km_labels"]==1]
df[,C(df["km_labels"]==1)]
df[,c(df["km_labels"]==1)]
df["km_labels"]==1
df[df["km_labels"]==1]
df[,"km"][1]
df["km"]
df["km"]
df
